{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[v0.14]영상처리_이미지 유사도 비교 외 실습.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOITDeqa46fLEHm/xKD/bp2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gani0325/2022/blob/main/Image%20processing/%5Bv0_14%5D%EC%98%81%EC%83%81%EC%B2%98%EB%A6%AC_%EC%9D%B4%EB%AF%B8%EC%A7%80_%EC%9C%A0%EC%82%AC%EB%8F%84_%EB%B9%84%EA%B5%90_%EC%99%B8_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [v0.14]영상처리_이미지 유사도 비교 외 실습\n",
        "\n",
        "https://alpaca-gt.tistory.com/93?category=895871"
      ],
      "metadata": {
        "id": "JKmAaKJ4c4YU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 이미지 유사도 비교 실습"
      ],
      "metadata": {
        "id": "izDe5dMic8R3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQQM3-TKc0Zs"
      },
      "outputs": [],
      "source": [
        "# 히스토그램 비교\n",
        "import cv2, numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "\n",
        "img1 = cv2.imread('img/hobbang.jpeg')\n",
        "img2 = cv2.imread('img/hobbang1.jpg')\n",
        "img3 = cv2.imread('img/hobbang2.jpeg')\n",
        "img4 = cv2.imread('img/jadu.jpg')\n",
        "\n",
        "# ----------img resize---------------------\n",
        "img2 = cv2.resize(img2, dsize = (197, 256))\n",
        "img3 = cv2.resize(img3, dsize = (197, 256))\n",
        "img4 = cv2.resize(img4, dsize = (197, 256))\n",
        "\n",
        "cv2.imshow('query', img1)\n",
        "imgs = [img1, img2, img3, img4]\n",
        "hists = []\n",
        "for i, img in enumerate(imgs) :\n",
        "    plt.subplot(1,len(imgs),i+1)\n",
        "    plt.title('img%d'% (i+1))\n",
        "    plt.axis('off') \n",
        "    plt.imshow(img[:,:,::-1])\n",
        "    #---① 각 이미지를 HSV로 변환\n",
        "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "    #---② H,S 채널에 대한 히스토그램 계산\n",
        "    hist = cv2.calcHist([hsv], [0,1], None, [180,256], [0,180,0, 256])\n",
        "    #---③ 0~1로 정규화\n",
        "    cv2.normalize(hist, hist, 0, 1, cv2.NORM_MINMAX)\n",
        "    hists.append(hist)\n",
        "\n",
        "\n",
        "query = hists[0]\n",
        "methods = {'CORREL' :cv2.HISTCMP_CORREL, 'CHISQR':cv2.HISTCMP_CHISQR, \n",
        "           'INTERSECT':cv2.HISTCMP_INTERSECT,\n",
        "           'BHATTACHARYYA':cv2.HISTCMP_BHATTACHARYYA}\n",
        "for j, (name, flag) in enumerate(methods.items()):\n",
        "    print('%-10s'%name, end='\\t')\n",
        "    for i, (hist, img) in enumerate(zip(hists, imgs)):\n",
        "        #---④ 각 메서드에 따라 img1과 각 이미지의 히스토그램 비교\n",
        "        ret = cv2.compareHist(query, hist, flag)\n",
        "        if flag == cv2.HISTCMP_INTERSECT: #교차 분석인 경우 \n",
        "            ret = ret/np.sum(query)        #비교대상으로 나누어 1로 정규화\n",
        "        print(\"img%d:%7.2f\"% (i+1 , ret), end='\\t')\n",
        "    print()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 해골 얼굴과 사자 합성 실습"
      ],
      "metadata": {
        "id": "_rQDi0zRdBAQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 해골 얼굴과 사자 합성하기\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 영상의 15%를 알파 블렌딩의 범위로 지정\n",
        "alpha_width_rate = 15\n",
        "\n",
        "# 합성할 두 영상 읽기\n",
        "img_bone = cv2.imread('img/bone.jpg')\n",
        "img_rion = cv2.imread('img/rion.jpg')\n",
        "\n",
        "# ----------img resize---------------------\n",
        "img_rion = cv2.resize(img_rion, dsize = (728, 607))\n",
        "\n",
        "# 입력 영상과 같은 크기의 결과 영상 준비\n",
        "img_comp = np.zeros_like(img_bone)\n",
        "\n",
        "# 연산에 필요한 좌표 계산\n",
        "height, width = img_bone.shape[:2]\n",
        "middle = width//2                             # 영상의 중앙 좌표\n",
        "alpha_width = width * alpha_width_rate // 100 # 알파 블렌딩 범위\n",
        "start = middle - alpha_width//2               # 알파 블렌딩 시작 지점\n",
        "step = 100/alpha_width                        # 알파 값 간격\n",
        "\n",
        "# 입력 영상의 절반씩 복사해서 결과 영상에 합성\n",
        "img_comp[:, :middle, : ] = img_bone[:, :middle, :].copy()\n",
        "img_comp[:, middle:, :] = img_rion[:, middle:, :].copy()\n",
        "cv2.imshow('half', img_comp)\n",
        "\n",
        "# 알파 값을 바꾸면서 알파 블렌딩 적용\n",
        "for i in range(alpha_width+1 ):\n",
        "    alpha = (100 - step * i) / 100  # 증감 간격에 따른 알파 값 (1~0)\n",
        "    beta = 1 - alpha                # 베타 값 (0~1)\n",
        "    # 알파 블렌딩 적용\n",
        "    img_comp[:, start+i] = img_bone[:, start+i] * \\\n",
        "                                alpha + img_rion[:, start+i] * beta\n",
        "    print(i, alpha, beta)\n",
        "    \n",
        "cv2.imshow('half bone', img_comp)\n",
        "cv2.waitKey()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "Oz_xv5FodBd8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. 움직임 감지 CCTV 만들기 실습"
      ],
      "metadata": {
        "id": "0uv65M30dEgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모션 감지 CCTV \n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# 감도 설정(카메라 품질에 따라 조정 필요)\n",
        "thresh = 35    # 달라진 픽셀 값 기준치 설정\n",
        "max_diff = 10   # 달라진 픽셀 갯수 기준치 설정\n",
        "\n",
        "# 카메라 캡션 장치 준비\n",
        "a, b, c = None, None, None\n",
        "cap = cv2.VideoCapture(0)\n",
        "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 480)      # 프레임 폭을 480으로 설정 \n",
        "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 320)     # 프레임 높이를 320으로 설정\n",
        "\n",
        "if cap.isOpened():\n",
        "    ret, a = cap.read()         # a 프레임 읽기\n",
        "    ret, b = cap.read()         # b 프레임 읽기\n",
        "\n",
        "    while ret:\n",
        "        ret, c = cap.read()     # c 프레임 읽기\n",
        "        draw = c.copy()         # 출력 영상에 사용할 복제본\n",
        "        if not ret:\n",
        "            break\n",
        "        \n",
        "        # 3개의 영상을 그레이 스케일로 변경\n",
        "        a_gray = cv2.cvtColor(a, cv2.COLOR_BGR2GRAY)\n",
        "        b_gray = cv2.cvtColor(b, cv2.COLOR_BGR2GRAY)\n",
        "        c_gray = cv2.cvtColor(c, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # a-b, b-c 절대 값 차 구하기 \n",
        "        diff1 = cv2.absdiff(a_gray, b_gray)\n",
        "        diff2 = cv2.absdiff(b_gray, c_gray)\n",
        "\n",
        "        # 스레시홀드로 기준치 이내의 차이는 무시\n",
        "        ret, diff1_t = cv2.threshold(diff1, thresh, 255, cv2.THRESH_BINARY)\n",
        "        ret, diff2_t = cv2.threshold(diff2, thresh, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        # 두 차이에 대해서 AND 연산, 두 영상의 차이가 모두 발견된 경우\n",
        "        diff = cv2.bitwise_and(diff1_t, diff2_t)\n",
        "\n",
        "        # 열림 연산으로 노이즈 제거 ---①\n",
        "        k = cv2.getStructuringElement(cv2.MORPH_CROSS, (3,3))\n",
        "        diff = cv2.morphologyEx(diff, cv2.MORPH_OPEN, k)\n",
        "\n",
        "        # 차이가 발생한 픽셀이 갯수 판단 후 사각형 그리기\n",
        "        diff_cnt = cv2.countNonZero(diff)\n",
        "        if diff_cnt > max_diff:\n",
        "            nzero = np.nonzero(diff)  # 0이 아닌 픽셀의 좌표 얻기(y[...], x[...])\n",
        "            cv2.rectangle(draw, (min(nzero[1]), min(nzero[0])), \\\n",
        "                                (max(nzero[1]), max(nzero[0])), (0,255,0), 2)\n",
        "            cv2.putText(draw, \"Motion Detected\", (10,30), \\\n",
        "                                cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,0,255))\n",
        "        \n",
        "        # 컬러 스케일 영상과 스레시홀드 영상을 통합해서 출력\n",
        "        stacked = np.hstack((draw, cv2.cvtColor(diff, cv2.COLOR_GRAY2BGR)))\n",
        "        cv2.imshow('motion sensor',stacked )\n",
        "\n",
        "        # 다음 비교를 위해 영상 순서 정리\n",
        "        a = b\n",
        "        b = c\n",
        "        \n",
        "        if cv2.waitKey(1) & 0xFF == 27:\n",
        "            break"
      ],
      "metadata": {
        "id": "MG5_as83dFAF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}