{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gani0325/2022/blob/main/BOAZ/%EB%AF%B8%EB%8B%88%ED%94%8C%EC%A0%9D2%EC%9B%94/%EB%AA%A8%EB%8D%B83%EA%B0%9C%EB%8B%A4%EA%B0%99%EC%9D%B4voting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr8XbLlQWggn",
        "outputId": "db4db21a-4f1e-448e-e9ca-e36597d13ffa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LhdkbOP6WjI7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4nB6BAKjyvq",
        "outputId": "1a0d450c-b38e-4d51-f7bb-0f79f67371e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-2.10.0-py3-none-any.whl (308 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 20 kB 33.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 30 kB 40.1 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 40 kB 17.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 51 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 61 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 71 kB 12.9 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 81 kB 14.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 92 kB 15.8 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 102 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 112 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 122 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 133 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 143 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 153 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 163 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 174 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 184 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 194 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 204 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 215 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 225 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 235 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 245 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 256 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 266 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 276 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 286 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 296 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 307 kB 13.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 308 kB 13.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.5)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.62.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Collecting cmaes>=0.8.2\n",
            "  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n",
            "Collecting cliff\n",
            "  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n",
            "\u001b[K     |████████████████████████████████| 81 kB 8.5 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.7.6-py3-none-any.whl (210 kB)\n",
            "\u001b[K     |████████████████████████████████| 210 kB 72.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.7)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.4.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.9 MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "  Downloading pbr-5.8.1-py2.py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 77.9 MB/s \n",
            "\u001b[?25hCollecting stevedore>=2.0.1\n",
            "  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.1.1)\n",
            "Collecting autopage>=0.4.0\n",
            "  Downloading autopage-0.5.0-py3-none-any.whl (29 kB)\n",
            "Collecting cmd2>=1.0.0\n",
            "  Downloading cmd2-2.4.0-py3-none-any.whl (150 kB)\n",
            "\u001b[K     |████████████████████████████████| 150 kB 58.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (3.10.0.2)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n",
            "Building wheels for collected packages: pyperclip\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=3d01e45a8d72f1e9d3706b87e7185e98581e4d6ccd58798be3f76eadcdeb1c2b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n",
            "Successfully built pyperclip\n",
            "Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n",
            "Successfully installed Mako-1.1.6 alembic-1.7.6 autopage-0.5.0 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.0 colorlog-6.6.0 optuna-2.10.0 pbr-5.8.1 pyperclip-1.8.2 stevedore-3.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "0-JT0FE4m0Aa"
      },
      "outputs": [],
      "source": [
        "import optuna\n",
        "from optuna import Trial, visualization\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2sJYOg7YslV"
      },
      "source": [
        "# RandomForest 최종"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rzSy8JFqW0UL"
      },
      "outputs": [],
      "source": [
        "test_fast = pd.read_csv(\"/content/drive/MyDrive/가은/BOAZ/미니플젝_2022_02/test_fast_final.csv\")\n",
        "test_slow = pd.read_csv(\"/content/drive/MyDrive/가은/BOAZ/미니플젝_2022_02/test_slow_final.csv\")\n",
        "\n",
        "train_fast = pd.read_csv(\"/content/drive/MyDrive/가은/BOAZ/미니플젝_2022_02/train_fast_final.csv\")\n",
        "train_slow = pd.read_csv(\"/content/drive/MyDrive/가은/BOAZ/미니플젝_2022_02/train_slow_final.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn1QxJBNZTac",
        "outputId": "edd9de67-26c9-40cc-ba7e-ffef7951986e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((102316, 68), (25575, 68), (102294, 68), (25575, 68))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_fast.shape, test_fast.shape, train_slow.shape, test_slow.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty1eSYUpb64B"
      },
      "source": [
        "## 급속 충전기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5gTnRdSlaRc_"
      },
      "outputs": [],
      "source": [
        "X_fast_train = train_fast.drop(['fast_exist'], axis=1)\n",
        "y_fast_train = train_fast.fast_exist\n",
        "\n",
        "X_fast_test = test_fast.drop(['fast_exist'], axis=1)\n",
        "y_fast_test = test_fast.fast_exist"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "# SelctKBest k=10\n",
        "select = SelectKBest(chi2, k=30)\n",
        "select.fit(X_fast_train, y_fast_train)\n",
        "\n",
        "# 선택한 특성\n",
        "f_scores = pd.DataFrame()\n",
        "\n",
        "f_scores['chi'] = select.scores_\n",
        "f_scores['p'] = select.pvalues_\n",
        "f_scores['support'] = select.get_support()\n",
        "f_scores['attribute'] = X_fast_train.columns\n",
        "f_scores[f_scores['support'] == True]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "J-gch1EH0RA2",
        "outputId": "d828537a-e532-40e5-ecab-f756a8fe58a4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7062d91f-e25f-4c9a-8aaa-64fac0e9b409\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chi</th>\n",
              "      <th>p</th>\n",
              "      <th>support</th>\n",
              "      <th>attribute</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>18210.932711</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>편의시설_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20045.894649</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>청소년관련시설_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>21260.349824</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>차량수_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>15913.034653</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>주차장_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>23806.979725</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>인구_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>21680.643277</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>의료시설_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>18139.716003</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>위락시설_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>14709.087896</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>완속_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19236.928835</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>업무시설_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>18655.930284</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>숙박시설_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>18529.692851</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>면적_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>18986.392099</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>계획부지_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>19983.475634</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>taxiStation_scaled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>14999.021966</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>busStation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>15697.759353</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>dw_lanes_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>17677.374538</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>dw_lanes_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>19217.886228</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>dw_lanes_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>16825.194322</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>dw_lanes_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>15988.400915</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>up_lanes_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>17249.633319</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>up_lanes_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>19173.439644</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>up_lanes_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>18413.493508</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>up_lanes_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>15658.826778</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>width_1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>16285.145931</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>width_2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>17518.495909</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>width_3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>20198.598093</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>width_4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>16408.712209</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>급속</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>18022.191112</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>승용차</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>17589.829876</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>체력증진시설</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>17257.396305</td>\n",
              "      <td>0.0</td>\n",
              "      <td>True</td>\n",
              "      <td>화물차</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7062d91f-e25f-4c9a-8aaa-64fac0e9b409')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7062d91f-e25f-4c9a-8aaa-64fac0e9b409 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7062d91f-e25f-4c9a-8aaa-64fac0e9b409');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             chi    p  support           attribute\n",
              "2   18210.932711  0.0     True         편의시설_scaled\n",
              "4   20045.894649  0.0     True      청소년관련시설_scaled\n",
              "6   21260.349824  0.0     True          차량수_scaled\n",
              "7   15913.034653  0.0     True          주차장_scaled\n",
              "12  23806.979725  0.0     True           인구_scaled\n",
              "13  21680.643277  0.0     True         의료시설_scaled\n",
              "15  18139.716003  0.0     True         위락시설_scaled\n",
              "17  14709.087896  0.0     True           완속_scaled\n",
              "18  19236.928835  0.0     True         업무시설_scaled\n",
              "19  18655.930284  0.0     True         숙박시설_scaled\n",
              "25  18529.692851  0.0     True           면적_scaled\n",
              "37  18986.392099  0.0     True         계획부지_scaled\n",
              "43  19983.475634  0.0     True  taxiStation_scaled\n",
              "45  14999.021966  0.0     True          busStation\n",
              "47  15697.759353  0.0     True          dw_lanes_1\n",
              "48  17677.374538  0.0     True          dw_lanes_2\n",
              "49  19217.886228  0.0     True          dw_lanes_3\n",
              "50  16825.194322  0.0     True          dw_lanes_4\n",
              "51  15988.400915  0.0     True          up_lanes_1\n",
              "52  17249.633319  0.0     True          up_lanes_2\n",
              "53  19173.439644  0.0     True          up_lanes_3\n",
              "54  18413.493508  0.0     True          up_lanes_4\n",
              "55  15658.826778  0.0     True             width_1\n",
              "56  16285.145931  0.0     True             width_2\n",
              "57  17518.495909  0.0     True             width_3\n",
              "58  20198.598093  0.0     True             width_4\n",
              "59  16408.712209  0.0     True                  급속\n",
              "61  18022.191112  0.0     True                 승용차\n",
              "64  17589.829876  0.0     True              체력증진시설\n",
              "66  17257.396305  0.0     True                 화물차"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 선택한 특성만 저장\n",
        "#X_train_select = select.transform(X_fast_train)\n",
        "#X_test_select = select.transform(X_fast_test)"
      ],
      "metadata": {
        "id": "Thr6ZoWp1PTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WgCuzhfpuJY",
        "outputId": "2041ccbc-844d-43c1-ff91-1992eb65d6d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-02-25 04:02:29,328]\u001b[0m A new study created in memory with name: no-name-7933c02e-d93b-4264-9263-e582db1c6c9e\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:04:36,092]\u001b[0m Trial 0 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 7609, 'max_features': 'sqrt', 'max_leaf_nodes': 8797, 'n_estimators': 216}. Best is trial 0 with value: 0.6190476190476191.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:06:21,365]\u001b[0m Trial 1 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'False', 'max_depth': 464, 'max_features': 'log2', 'max_leaf_nodes': 268, 'n_estimators': 282}. Best is trial 0 with value: 0.6190476190476191.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:10:02,269]\u001b[0m Trial 2 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 9697, 'max_features': 'log2', 'max_leaf_nodes': 2371, 'n_estimators': 606}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:11:55,319]\u001b[0m Trial 3 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'False', 'max_depth': 2889, 'max_features': 'log2', 'max_leaf_nodes': 9206, 'n_estimators': 306}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:15:18,093]\u001b[0m Trial 4 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 9063, 'max_features': 'auto', 'max_leaf_nodes': 7895, 'n_estimators': 380}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:17:20,289]\u001b[0m Trial 5 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 3867, 'max_features': 'log2', 'max_leaf_nodes': 158, 'n_estimators': 332}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:25:51,039]\u001b[0m Trial 6 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'False', 'max_depth': 929, 'max_features': 'auto', 'max_leaf_nodes': 4440, 'n_estimators': 965}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:26:18,681]\u001b[0m Trial 7 finished with value: 0.5714285714285713 and parameters: {'bootstrap': 'True', 'max_depth': 5132, 'max_features': 'log2', 'max_leaf_nodes': 8348, 'n_estimators': 74}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:28:23,222]\u001b[0m Trial 8 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'False', 'max_depth': 2042, 'max_features': 'sqrt', 'max_leaf_nodes': 8512, 'n_estimators': 237}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:35:26,711]\u001b[0m Trial 9 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'False', 'max_depth': 3822, 'max_features': 'auto', 'max_leaf_nodes': 3284, 'n_estimators': 814}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:39:04,136]\u001b[0m Trial 10 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 6937, 'max_features': 'log2', 'max_leaf_nodes': 2359, 'n_estimators': 598}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:43:54,373]\u001b[0m Trial 11 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 9858, 'max_features': 'auto', 'max_leaf_nodes': 6198, 'n_estimators': 553}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:49:51,138]\u001b[0m Trial 12 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'False', 'max_depth': 9986, 'max_features': 'auto', 'max_leaf_nodes': 6665, 'n_estimators': 682}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 04:53:49,616]\u001b[0m Trial 13 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 8024, 'max_features': 'auto', 'max_leaf_nodes': 2389, 'n_estimators': 455}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:00:17,198]\u001b[0m Trial 14 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 8575, 'max_features': 'sqrt', 'max_leaf_nodes': 6546, 'n_estimators': 743}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:03:02,586]\u001b[0m Trial 15 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 6061, 'max_features': 'log2', 'max_leaf_nodes': 4860, 'n_estimators': 453}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:06:49,479]\u001b[0m Trial 16 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'False', 'max_depth': 8961, 'max_features': 'auto', 'max_leaf_nodes': 7422, 'n_estimators': 433}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:07:10,713]\u001b[0m Trial 17 finished with value: 0.6046511627906976 and parameters: {'bootstrap': 'True', 'max_depth': 6421, 'max_features': 'log2', 'max_leaf_nodes': 1482, 'n_estimators': 57}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:10:56,048]\u001b[0m Trial 18 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 5795, 'max_features': 'log2', 'max_leaf_nodes': 4493, 'n_estimators': 620}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:16:00,157]\u001b[0m Trial 19 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 5166, 'max_features': 'log2', 'max_leaf_nodes': 3976, 'n_estimators': 838}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:19:06,673]\u001b[0m Trial 20 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 6792, 'max_features': 'log2', 'max_leaf_nodes': 5499, 'n_estimators': 512}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:23:07,464]\u001b[0m Trial 21 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 6322, 'max_features': 'log2', 'max_leaf_nodes': 5154, 'n_estimators': 663}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:26:41,193]\u001b[0m Trial 22 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 7428, 'max_features': 'log2', 'max_leaf_nodes': 2464, 'n_estimators': 588}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:29:47,880]\u001b[0m Trial 23 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 7515, 'max_features': 'log2', 'max_leaf_nodes': 1538, 'n_estimators': 514}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:32:52,490]\u001b[0m Trial 24 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 8267, 'max_features': 'log2', 'max_leaf_nodes': 1146, 'n_estimators': 508}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:37:17,056]\u001b[0m Trial 25 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 8468, 'max_features': 'log2', 'max_leaf_nodes': 1053, 'n_estimators': 733}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:43:47,758]\u001b[0m Trial 26 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 9354, 'max_features': 'sqrt', 'max_leaf_nodes': 1151, 'n_estimators': 752}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:46:57,890]\u001b[0m Trial 27 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 8045, 'max_features': 'log2', 'max_leaf_nodes': 3257, 'n_estimators': 524}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 05:52:53,253]\u001b[0m Trial 28 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 9455, 'max_features': 'log2', 'max_leaf_nodes': 3323, 'n_estimators': 981}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:00:15,032]\u001b[0m Trial 29 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'False', 'max_depth': 8762, 'max_features': 'auto', 'max_leaf_nodes': 7590, 'n_estimators': 846}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:03:35,537]\u001b[0m Trial 30 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 7683, 'max_features': 'sqrt', 'max_leaf_nodes': 3404, 'n_estimators': 377}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:06:18,690]\u001b[0m Trial 31 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 8536, 'max_features': 'log2', 'max_leaf_nodes': 877, 'n_estimators': 445}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:07:17,372]\u001b[0m Trial 32 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 8170, 'max_features': 'log2', 'max_leaf_nodes': 749, 'n_estimators': 157}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:10:06,028]\u001b[0m Trial 33 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 6785, 'max_features': 'log2', 'max_leaf_nodes': 5899, 'n_estimators': 462}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:13:37,545]\u001b[0m Trial 34 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 6619, 'max_features': 'log2', 'max_leaf_nodes': 5818, 'n_estimators': 583}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:17:07,038]\u001b[0m Trial 35 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 5776, 'max_features': 'log2', 'max_leaf_nodes': 5855, 'n_estimators': 577}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:20:49,559]\u001b[0m Trial 36 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 5710, 'max_features': 'log2', 'max_leaf_nodes': 7028, 'n_estimators': 613}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:23:08,292]\u001b[0m Trial 37 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 4198, 'max_features': 'log2', 'max_leaf_nodes': 4332, 'n_estimators': 379}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:27:07,402]\u001b[0m Trial 38 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'False', 'max_depth': 4554, 'max_features': 'log2', 'max_leaf_nodes': 5775, 'n_estimators': 658}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:30:25,756]\u001b[0m Trial 39 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 5901, 'max_features': 'log2', 'max_leaf_nodes': 4713, 'n_estimators': 546}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:34:46,131]\u001b[0m Trial 40 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 2848, 'max_features': 'sqrt', 'max_leaf_nodes': 5198, 'n_estimators': 496}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:39:11,646]\u001b[0m Trial 41 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 7202, 'max_features': 'log2', 'max_leaf_nodes': 1786, 'n_estimators': 732}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:41:17,505]\u001b[0m Trial 42 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'False', 'max_depth': 5592, 'max_features': 'log2', 'max_leaf_nodes': 9958, 'n_estimators': 343}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:44:39,127]\u001b[0m Trial 43 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 7391, 'max_features': 'sqrt', 'max_leaf_nodes': 3876, 'n_estimators': 382}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:46:53,593]\u001b[0m Trial 44 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 7479, 'max_features': 'sqrt', 'max_leaf_nodes': 2668, 'n_estimators': 255}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:47:31,926]\u001b[0m Trial 45 finished with value: 0.04930332261521972 and parameters: {'bootstrap': 'True', 'max_depth': 7300, 'max_features': 'sqrt', 'max_leaf_nodes': 5, 'n_estimators': 500}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:51:03,054]\u001b[0m Trial 46 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 8142, 'max_features': 'sqrt', 'max_leaf_nodes': 1865, 'n_estimators': 403}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 06:55:17,234]\u001b[0m Trial 47 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 8178, 'max_features': 'log2', 'max_leaf_nodes': 507, 'n_estimators': 704}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:03:24,648]\u001b[0m Trial 48 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 9201, 'max_features': 'sqrt', 'max_leaf_nodes': 1859, 'n_estimators': 940}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:04:55,074]\u001b[0m Trial 49 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 7840, 'max_features': 'sqrt', 'max_leaf_nodes': 405, 'n_estimators': 173}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:06:46,519]\u001b[0m Trial 50 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 8527, 'max_features': 'log2', 'max_leaf_nodes': 980, 'n_estimators': 303}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:09:39,350]\u001b[0m Trial 51 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 8575, 'max_features': 'log2', 'max_leaf_nodes': 1342, 'n_estimators': 460}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:12:12,930]\u001b[0m Trial 52 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 7740, 'max_features': 'log2', 'max_leaf_nodes': 3003, 'n_estimators': 419}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:15:32,334]\u001b[0m Trial 53 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 6718, 'max_features': 'log2', 'max_leaf_nodes': 2944, 'n_estimators': 555}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:18:54,367]\u001b[0m Trial 54 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 6412, 'max_features': 'log2', 'max_leaf_nodes': 3077, 'n_estimators': 562}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:22:02,988]\u001b[0m Trial 55 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 8905, 'max_features': 'auto', 'max_leaf_nodes': 3846, 'n_estimators': 359}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:25:51,876]\u001b[0m Trial 56 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 5421, 'max_features': 'log2', 'max_leaf_nodes': 6791, 'n_estimators': 639}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:29:36,640]\u001b[0m Trial 57 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 4111, 'max_features': 'log2', 'max_leaf_nodes': 7970, 'n_estimators': 625}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:32:25,255]\u001b[0m Trial 58 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 4408, 'max_features': 'log2', 'max_leaf_nodes': 9118, 'n_estimators': 466}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:37:12,638]\u001b[0m Trial 59 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 7230, 'max_features': 'log2', 'max_leaf_nodes': 1944, 'n_estimators': 798}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:40:20,628]\u001b[0m Trial 60 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 6978, 'max_features': 'log2', 'max_leaf_nodes': 2217, 'n_estimators': 521}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:42:57,079]\u001b[0m Trial 61 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 6576, 'max_features': 'log2', 'max_leaf_nodes': 5938, 'n_estimators': 432}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:46:27,919]\u001b[0m Trial 62 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'False', 'max_depth': 6921, 'max_features': 'log2', 'max_leaf_nodes': 5412, 'n_estimators': 585}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:48:23,054]\u001b[0m Trial 63 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'False', 'max_depth': 6187, 'max_features': 'log2', 'max_leaf_nodes': 5936, 'n_estimators': 315}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:54:28,971]\u001b[0m Trial 64 finished with value: 0.6190476190476191 and parameters: {'bootstrap': 'True', 'max_depth': 8244, 'max_features': 'auto', 'max_leaf_nodes': 624, 'n_estimators': 706}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 07:57:38,932]\u001b[0m Trial 65 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 9457, 'max_features': 'log2', 'max_leaf_nodes': 1523, 'n_estimators': 526}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 08:01:14,808]\u001b[0m Trial 66 finished with value: 0.6511627906976745 and parameters: {'bootstrap': 'True', 'max_depth': 9484, 'max_features': 'sqrt', 'max_leaf_nodes': 1557, 'n_estimators': 413}. Best is trial 2 with value: 0.6511627906976745.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#Optuna\n",
        "from pandas.core.common import random_state\n",
        "\n",
        "def RF_objective(trial):\n",
        "    bootstrap = trial.suggest_categorical('bootstrap',['True','False'])\n",
        "    max_depth = trial.suggest_int('max_depth', 1, 10000)\n",
        "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt','log2'])\n",
        "    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 1, 10000)\n",
        "    n_estimators =  trial.suggest_int('n_estimators', 30, 1000)\n",
        "   \n",
        "    model = RandomForestClassifier(bootstrap = bootstrap,\n",
        "                                 max_depth = max_depth, max_features = max_features,\n",
        "                                 max_leaf_nodes = max_leaf_nodes,n_estimators = n_estimators,n_jobs=2,random_state=25)\n",
        "\n",
        "    \n",
        "    model.fit(X_train_select30, y_fast_train)    \n",
        "    y_fast_pred = model.predict(X_test_select30)\n",
        "    f1 = f1_score(y_fast_test, y_fast_pred)\n",
        "  \n",
        "\n",
        "    return f1\n",
        "    \n",
        "#Execute optuna and set hyperparameters\n",
        "RF_study = optuna.create_study(direction='maximize')\n",
        "RF_study.optimize(RF_objective, n_trials=250)\n",
        "\n",
        "#Create an instance with tuned hyperparameters\n",
        "optimized_RF = RandomForestClassifier(max_depth = RF_study.best_params['max_depth'], max_leaf_nodes = RF_study.best_params['max_leaf_nodes'],\n",
        "                                      n_estimators = RF_study.best_params['n_estimators'],n_jobs=2,max_features =RF_study.best_params['max_features'],\n",
        "                                      bootstrap= RF_study.best_params['bootstrap'],random_state=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6im4R6sQtgSA",
        "outputId": "f5836216-5c7c-4567-d047-bcc2d7f9ba9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=2699, max_leaf_nodes=172, n_estimators=31,\n",
              "                       random_state=25)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "model = RandomForestClassifier(random_state=25, n_estimators=31, max_depth=2699, max_leaf_nodes=172,bootstrap = True, max_features = 'auto')\n",
        "model.fit(X_fast_train, y_fast_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAEOO1-WmYZO",
        "outputId": "1d11e337-6a03-44b4-c3c7-8c4c8d087aae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train_preds = model.predict(X_fast_train)\n",
        "f1 = f1_score(train_preds,y_fast_train)\n",
        "f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3HwDJPnrBme",
        "outputId": "7af9324a-6cb2-4358-94a8-1c17692b0ac1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666665"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        " y_fast_pred = model.predict(X_fast_test)\n",
        " f1 = f1_score(y_fast_test, y_fast_pred)\n",
        " f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XdM6Jtn3z8Xf"
      },
      "outputs": [],
      "source": [
        "y_fast_prob = model.predict_proba(X_fast_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYPvbN820Sfe",
        "outputId": "ad341886-1aaa-479a-b322-20bb56b6fc3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1 :0.44680851063829796\n",
            "0.2 :0.5352112676056338\n",
            "0.3 :0.6551724137931034\n",
            "0.4 :0.7083333333333334\n",
            "0.5 :0.6666666666666665\n",
            "0.6 :0.5499999999999999\n",
            "0.7 :0.48648648648648657\n",
            "0.8 :0.36363636363636365\n",
            "0.9 :0.21428571428571425\n"
          ]
        }
      ],
      "source": [
        "for threshold in range(1,10):\n",
        "    threshold = round(threshold*0.1, 1)\n",
        "    y_fast_pred = np.where(y_fast_prob>=threshold, 1, 0)\n",
        "    print(f'{threshold} :{f1_score(y_fast_test, y_fast_pred[:,1])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tuning 후 feature selection (10~65)"
      ],
      "metadata": {
        "id": "5srZ8L0vR5EI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ks = [10,15,20,25,30,35,40,45,50,55,60,65]"
      ],
      "metadata": {
        "id": "r9qF_7dfR4sX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### fast\n",
        "* 최적 score = 0.7186\n",
        "* 최적 k = 60\n",
        "* 최적 threshold = 0.3"
      ],
      "metadata": {
        "id": "KrgcjyCsR9-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in ks:\n",
        "    fit = SelectKBest(chi2, k=k).fit(X_fast_train, y_fast_train)\n",
        "    new_X_fast_train = fit.transform(X_fast_train)\n",
        "    new_X_fast_test = fit.transform(X_fast_test)\n",
        "    \n",
        "    model.fit(new_X_fast_train, y_fast_train)\n",
        "    y_fast_prob = model.predict_proba(new_X_fast_test)\n",
        "    print(f'================================{k}================================')\n",
        "    for threshold in range(1,10):\n",
        "        threshold = round(threshold*0.1, 1)\n",
        "        y_fast_pred = np.where(y_fast_prob>=threshold, 1, 0)\n",
        "        print(f'{threshold} :{f1_score(y_fast_test, y_fast_pred[:,1])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5oSsMloR9fN",
        "outputId": "cce90464-7624-4f8d-f912-d5eafb412336"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================10================================\n",
            "0.1 :0.0286493860845839\n",
            "0.2 :0.28571428571428575\n",
            "0.3 :0.32608695652173914\n",
            "0.4 :0.37037037037037035\n",
            "0.5 :0.34782608695652173\n",
            "0.6 :0.3333333333333333\n",
            "0.7 :0.35294117647058826\n",
            "0.8 :0.4\n",
            "0.9 :0.45714285714285713\n",
            "================================15================================\n",
            "0.1 :0.4158415841584159\n",
            "0.2 :0.5833333333333334\n",
            "0.3 :0.6451612903225806\n",
            "0.4 :0.6538461538461539\n",
            "0.5 :0.6511627906976745\n",
            "0.6 :0.5499999999999999\n",
            "0.7 :0.5128205128205129\n",
            "0.8 :0.45714285714285713\n",
            "0.9 :0.47058823529411764\n",
            "================================20================================\n",
            "0.1 :0.4285714285714286\n",
            "0.2 :0.5675675675675675\n",
            "0.3 :0.6666666666666667\n",
            "0.4 :0.6071428571428571\n",
            "0.5 :0.56\n",
            "0.6 :0.48888888888888893\n",
            "0.7 :0.4444444444444444\n",
            "0.8 :0.3529411764705882\n",
            "0.9 :0.3125\n",
            "================================25================================\n",
            "0.1 :0.42\n",
            "0.2 :0.5675675675675675\n",
            "0.3 :0.6268656716417911\n",
            "0.4 :0.6101694915254237\n",
            "0.5 :0.5416666666666667\n",
            "0.6 :0.42857142857142855\n",
            "0.7 :0.41025641025641024\n",
            "0.8 :0.3783783783783784\n",
            "0.9 :0.30303030303030304\n",
            "================================30================================\n",
            "0.1 :0.3888888888888889\n",
            "0.2 :0.6086956521739131\n",
            "0.3 :0.6666666666666666\n",
            "0.4 :0.6274509803921569\n",
            "0.5 :0.5652173913043478\n",
            "0.6 :0.5238095238095238\n",
            "0.7 :0.47368421052631576\n",
            "0.8 :0.24242424242424243\n",
            "0.9 :0.20689655172413793\n",
            "================================35================================\n",
            "0.1 :0.44859813084112143\n",
            "0.2 :0.5753424657534247\n",
            "0.3 :0.6268656716417911\n",
            "0.4 :0.6415094339622641\n",
            "0.5 :0.45454545454545453\n",
            "0.6 :0.41025641025641024\n",
            "0.7 :0.4\n",
            "0.8 :0.3529411764705882\n",
            "0.9 :0.25806451612903225\n",
            "================================40================================\n",
            "0.1 :0.4285714285714286\n",
            "0.2 :0.6000000000000001\n",
            "0.3 :0.689655172413793\n",
            "0.4 :0.7169811320754718\n",
            "0.5 :0.64\n",
            "0.6 :0.5454545454545454\n",
            "0.7 :0.4210526315789474\n",
            "0.8 :0.3125\n",
            "0.9 :0.26666666666666666\n",
            "================================45================================\n",
            "0.1 :0.4329896907216495\n",
            "0.2 :0.5526315789473684\n",
            "0.3 :0.625\n",
            "0.4 :0.6153846153846153\n",
            "0.5 :0.5238095238095238\n",
            "0.6 :0.45\n",
            "0.7 :0.3783783783783784\n",
            "0.8 :0.29411764705882354\n",
            "0.9 :0.21428571428571425\n",
            "================================50================================\n",
            "0.1 :0.4150943396226415\n",
            "0.2 :0.5063291139240506\n",
            "0.3 :0.6031746031746031\n",
            "0.4 :0.6415094339622641\n",
            "0.5 :0.5777777777777778\n",
            "0.6 :0.4615384615384615\n",
            "0.7 :0.4117647058823529\n",
            "0.8 :0.36363636363636365\n",
            "0.9 :0.3225806451612903\n",
            "================================55================================\n",
            "0.1 :0.4444444444444444\n",
            "0.2 :0.5633802816901409\n",
            "0.3 :0.6440677966101696\n",
            "0.4 :0.68\n",
            "0.5 :0.6530612244897959\n",
            "0.6 :0.6363636363636364\n",
            "0.7 :0.4444444444444444\n",
            "0.8 :0.3225806451612903\n",
            "0.9 :0.21428571428571425\n",
            "================================60================================\n",
            "0.1 :0.423076923076923\n",
            "0.2 :0.619718309859155\n",
            "0.3 :0.711864406779661\n",
            "0.4 :0.7017543859649122\n",
            "0.5 :0.6808510638297872\n",
            "0.6 :0.5499999999999999\n",
            "0.7 :0.47368421052631576\n",
            "0.8 :0.45714285714285713\n",
            "0.9 :0.33333333333333337\n",
            "================================65================================\n",
            "0.1 :0.47524752475247517\n",
            "0.2 :0.6176470588235294\n",
            "0.3 :0.6785714285714285\n",
            "0.4 :0.7169811320754718\n",
            "0.5 :0.6666666666666666\n",
            "0.6 :0.6222222222222222\n",
            "0.7 :0.5128205128205129\n",
            "0.8 :0.45714285714285713\n",
            "0.9 :0.21428571428571425\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "================================40================================\n",
        "0.4 :0.7169811320754718\n",
        "\n",
        "================================65================================\n",
        "0.4 :0.7169811320754718\n",
        "```"
      ],
      "metadata": {
        "id": "TroiFEyLeHPv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGbyJeZVcAt9"
      },
      "source": [
        "## 완속 충전기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "YMpc0N--eT7L"
      },
      "outputs": [],
      "source": [
        "X_slow_train = train_slow.drop(['slow_exist'], axis=1)\n",
        "y_slow_train = train_slow.slow_exist\n",
        "\n",
        "X_slow_test = test_slow.drop(['slow_exist'], axis=1)\n",
        "y_slow_test = test_slow.slow_exist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CWLyBp5wDn_"
      },
      "source": [
        "# **Optuna**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "w6eUlfaywCmX",
        "outputId": "74d27e91-6567-452d-c82e-7c10ed3bf0bd"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2022-02-25 09:17:09,348]\u001b[0m A new study created in memory with name: no-name-34a263bf-53d6-437b-a0c6-d32100246e86\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 09:27:42,455]\u001b[0m Trial 0 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 6583, 'max_features': 'sqrt', 'max_leaf_nodes': 1497, 'n_estimators': 959}. Best is trial 0 with value: 0.7575757575757577.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 09:32:09,893]\u001b[0m Trial 1 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 5032, 'max_features': 'log2', 'max_leaf_nodes': 9436, 'n_estimators': 563}. Best is trial 0 with value: 0.7575757575757577.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 09:39:21,114]\u001b[0m Trial 2 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'False', 'max_depth': 5094, 'max_features': 'log2', 'max_leaf_nodes': 10000, 'n_estimators': 897}. Best is trial 0 with value: 0.7575757575757577.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 09:42:55,163]\u001b[0m Trial 3 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 5131, 'max_features': 'sqrt', 'max_leaf_nodes': 6679, 'n_estimators': 317}. Best is trial 0 with value: 0.7575757575757577.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 09:52:15,765]\u001b[0m Trial 4 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 4756, 'max_features': 'sqrt', 'max_leaf_nodes': 5721, 'n_estimators': 818}. Best is trial 0 with value: 0.7575757575757577.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 09:57:36,529]\u001b[0m Trial 5 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 2035, 'max_features': 'auto', 'max_leaf_nodes': 4747, 'n_estimators': 456}. Best is trial 0 with value: 0.7575757575757577.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:00:50,059]\u001b[0m Trial 6 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 1464, 'max_features': 'sqrt', 'max_leaf_nodes': 7049, 'n_estimators': 278}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:04:26,241]\u001b[0m Trial 7 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'False', 'max_depth': 8030, 'max_features': 'auto', 'max_leaf_nodes': 4018, 'n_estimators': 317}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:13:14,787]\u001b[0m Trial 8 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 309, 'max_features': 'auto', 'max_leaf_nodes': 8038, 'n_estimators': 784}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:13:52,678]\u001b[0m Trial 9 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 4826, 'max_features': 'log2', 'max_leaf_nodes': 5891, 'n_estimators': 78}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:14:35,545]\u001b[0m Trial 10 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'False', 'max_depth': 1859, 'max_features': 'sqrt', 'max_leaf_nodes': 2565, 'n_estimators': 65}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:20:59,618]\u001b[0m Trial 11 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 8702, 'max_features': 'sqrt', 'max_leaf_nodes': 191, 'n_estimators': 593}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:24:03,840]\u001b[0m Trial 12 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 6811, 'max_features': 'sqrt', 'max_leaf_nodes': 364, 'n_estimators': 281}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:34:40,086]\u001b[0m Trial 13 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 9765, 'max_features': 'sqrt', 'max_leaf_nodes': 2450, 'n_estimators': 968}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:42:36,831]\u001b[0m Trial 14 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'False', 'max_depth': 3241, 'max_features': 'sqrt', 'max_leaf_nodes': 7651, 'n_estimators': 734}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:44:43,724]\u001b[0m Trial 15 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'True', 'max_depth': 6363, 'max_features': 'sqrt', 'max_leaf_nodes': 2606, 'n_estimators': 197}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:49:24,077]\u001b[0m Trial 16 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 2912, 'max_features': 'sqrt', 'max_leaf_nodes': 1401, 'n_estimators': 406}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:57:01,391]\u001b[0m Trial 17 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 172, 'max_features': 'sqrt', 'max_leaf_nodes': 3960, 'n_estimators': 659}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 10:58:26,731]\u001b[0m Trial 18 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'False', 'max_depth': 6592, 'max_features': 'log2', 'max_leaf_nodes': 8080, 'n_estimators': 176}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 11:03:52,138]\u001b[0m Trial 19 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 3731, 'max_features': 'auto', 'max_leaf_nodes': 6688, 'n_estimators': 466}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 11:14:53,568]\u001b[0m Trial 20 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 1355, 'max_features': 'sqrt', 'max_leaf_nodes': 3673, 'n_estimators': 979}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 11:19:15,879]\u001b[0m Trial 21 finished with value: 0.2708333333333333 and parameters: {'bootstrap': 'True', 'max_depth': 25, 'max_features': 'sqrt', 'max_leaf_nodes': 3937, 'n_estimators': 623}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 11:24:21,874]\u001b[0m Trial 22 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 3839, 'max_features': 'auto', 'max_leaf_nodes': 6956, 'n_estimators': 442}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 11:35:57,555]\u001b[0m Trial 23 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 1693, 'max_features': 'sqrt', 'max_leaf_nodes': 2023, 'n_estimators': 999}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 11:46:21,403]\u001b[0m Trial 24 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 1214, 'max_features': 'sqrt', 'max_leaf_nodes': 1350, 'n_estimators': 901}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 11:50:50,480]\u001b[0m Trial 25 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 3932, 'max_features': 'auto', 'max_leaf_nodes': 6987, 'n_estimators': 387}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:00:53,428]\u001b[0m Trial 26 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'False', 'max_depth': 2578, 'max_features': 'sqrt', 'max_leaf_nodes': 1424, 'n_estimators': 877}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:08:55,354]\u001b[0m Trial 27 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 940, 'max_features': 'sqrt', 'max_leaf_nodes': 1046, 'n_estimators': 706}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:13:12,999]\u001b[0m Trial 28 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 5845, 'max_features': 'auto', 'max_leaf_nodes': 8794, 'n_estimators': 380}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:17:32,791]\u001b[0m Trial 29 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'False', 'max_depth': 2615, 'max_features': 'log2', 'max_leaf_nodes': 3167, 'n_estimators': 538}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:25:04,341]\u001b[0m Trial 30 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 7445, 'max_features': 'sqrt', 'max_leaf_nodes': 5021, 'n_estimators': 686}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:27:24,034]\u001b[0m Trial 31 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 687, 'max_features': 'auto', 'max_leaf_nodes': 9153, 'n_estimators': 216}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:29:05,609]\u001b[0m Trial 32 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'False', 'max_depth': 827, 'max_features': 'log2', 'max_leaf_nodes': 8869, 'n_estimators': 222}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:30:07,351]\u001b[0m Trial 33 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'True', 'max_depth': 7570, 'max_features': 'auto', 'max_leaf_nodes': 9940, 'n_estimators': 98}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:33:14,158]\u001b[0m Trial 34 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 7628, 'max_features': 'sqrt', 'max_leaf_nodes': 5948, 'n_estimators': 291}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:34:49,212]\u001b[0m Trial 35 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'False', 'max_depth': 957, 'max_features': 'log2', 'max_leaf_nodes': 8964, 'n_estimators': 211}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:36:19,568]\u001b[0m Trial 36 finished with value: 0.7272727272727272 and parameters: {'bootstrap': 'True', 'max_depth': 5489, 'max_features': 'auto', 'max_leaf_nodes': 5894, 'n_estimators': 141}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:39:16,188]\u001b[0m Trial 37 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 8247, 'max_features': 'sqrt', 'max_leaf_nodes': 5181, 'n_estimators': 274}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:42:09,265]\u001b[0m Trial 38 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 8927, 'max_features': 'sqrt', 'max_leaf_nodes': 5282, 'n_estimators': 267}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:45:49,677]\u001b[0m Trial 39 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 9924, 'max_features': 'auto', 'max_leaf_nodes': 4960, 'n_estimators': 337}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:48:42,050]\u001b[0m Trial 40 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 9164, 'max_features': 'sqrt', 'max_leaf_nodes': 5431, 'n_estimators': 263}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:51:40,953]\u001b[0m Trial 41 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 8626, 'max_features': 'sqrt', 'max_leaf_nodes': 6385, 'n_estimators': 275}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:54:48,083]\u001b[0m Trial 42 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 8488, 'max_features': 'sqrt', 'max_leaf_nodes': 6149, 'n_estimators': 289}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:58:26,514]\u001b[0m Trial 43 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 8215, 'max_features': 'sqrt', 'max_leaf_nodes': 4388, 'n_estimators': 331}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 12:59:52,758]\u001b[0m Trial 44 finished with value: 0.7500000000000001 and parameters: {'bootstrap': 'True', 'max_depth': 8412, 'max_features': 'sqrt', 'max_leaf_nodes': 5876, 'n_estimators': 134}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:00:13,391]\u001b[0m Trial 45 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'True', 'max_depth': 9039, 'max_features': 'sqrt', 'max_leaf_nodes': 6371, 'n_estimators': 32}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:03:07,104]\u001b[0m Trial 46 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 9378, 'max_features': 'sqrt', 'max_leaf_nodes': 7512, 'n_estimators': 252}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:05:57,384]\u001b[0m Trial 47 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 9375, 'max_features': 'sqrt', 'max_leaf_nodes': 7724, 'n_estimators': 252}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:11:26,120]\u001b[0m Trial 48 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 8624, 'max_features': 'sqrt', 'max_leaf_nodes': 6525, 'n_estimators': 486}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:13:13,719]\u001b[0m Trial 49 finished with value: 0.7500000000000001 and parameters: {'bootstrap': 'True', 'max_depth': 9460, 'max_features': 'sqrt', 'max_leaf_nodes': 7455, 'n_estimators': 160}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:16:43,330]\u001b[0m Trial 50 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 7287, 'max_features': 'sqrt', 'max_leaf_nodes': 8234, 'n_estimators': 309}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:19:38,822]\u001b[0m Trial 51 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 9043, 'max_features': 'sqrt', 'max_leaf_nodes': 7310, 'n_estimators': 251}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:23:50,353]\u001b[0m Trial 52 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 9403, 'max_features': 'sqrt', 'max_leaf_nodes': 7597, 'n_estimators': 363}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:26:36,800]\u001b[0m Trial 53 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 9464, 'max_features': 'sqrt', 'max_leaf_nodes': 7273, 'n_estimators': 246}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:27:48,799]\u001b[0m Trial 54 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'True', 'max_depth': 7953, 'max_features': 'auto', 'max_leaf_nodes': 6183, 'n_estimators': 108}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:30:42,914]\u001b[0m Trial 55 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 9663, 'max_features': 'sqrt', 'max_leaf_nodes': 8341, 'n_estimators': 250}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:33:10,606]\u001b[0m Trial 56 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 7809, 'max_features': 'log2', 'max_leaf_nodes': 9543, 'n_estimators': 304}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:35:56,207]\u001b[0m Trial 57 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 9006, 'max_features': 'sqrt', 'max_leaf_nodes': 7395, 'n_estimators': 239}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:41:08,071]\u001b[0m Trial 58 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 8627, 'max_features': 'sqrt', 'max_leaf_nodes': 5257, 'n_estimators': 437}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:45:58,043]\u001b[0m Trial 59 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 8374, 'max_features': 'sqrt', 'max_leaf_nodes': 4497, 'n_estimators': 414}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:48:02,496]\u001b[0m Trial 60 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'False', 'max_depth': 9609, 'max_features': 'auto', 'max_leaf_nodes': 8247, 'n_estimators': 180}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:51:23,745]\u001b[0m Trial 61 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 8842, 'max_features': 'sqrt', 'max_leaf_nodes': 6903, 'n_estimators': 293}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:53:45,140]\u001b[0m Trial 62 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 9942, 'max_features': 'sqrt', 'max_leaf_nodes': 7153, 'n_estimators': 209}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 13:57:39,069]\u001b[0m Trial 63 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 7149, 'max_features': 'sqrt', 'max_leaf_nodes': 5492, 'n_estimators': 346}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:01:02,022]\u001b[0m Trial 64 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 4567, 'max_features': 'sqrt', 'max_leaf_nodes': 5668, 'n_estimators': 297}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:02:50,773]\u001b[0m Trial 65 finished with value: 0.7500000000000001 and parameters: {'bootstrap': 'True', 'max_depth': 2258, 'max_features': 'sqrt', 'max_leaf_nodes': 8506, 'n_estimators': 162}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:05:08,464]\u001b[0m Trial 66 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 539, 'max_features': 'auto', 'max_leaf_nodes': 9074, 'n_estimators': 210}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:07:56,500]\u001b[0m Trial 67 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 9319, 'max_features': 'sqrt', 'max_leaf_nodes': 7870, 'n_estimators': 247}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:10:43,479]\u001b[0m Trial 68 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 9346, 'max_features': 'sqrt', 'max_leaf_nodes': 7832, 'n_estimators': 253}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:11:38,843]\u001b[0m Trial 69 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 9651, 'max_features': 'log2', 'max_leaf_nodes': 8581, 'n_estimators': 121}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:15:30,827]\u001b[0m Trial 70 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'False', 'max_depth': 8869, 'max_features': 'sqrt', 'max_leaf_nodes': 6187, 'n_estimators': 356}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:17:32,173]\u001b[0m Trial 71 finished with value: 0.7500000000000001 and parameters: {'bootstrap': 'True', 'max_depth': 9962, 'max_features': 'sqrt', 'max_leaf_nodes': 6725, 'n_estimators': 186}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:20:04,083]\u001b[0m Trial 72 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 8579, 'max_features': 'sqrt', 'max_leaf_nodes': 7246, 'n_estimators': 234}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:23:09,342]\u001b[0m Trial 73 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 8213, 'max_features': 'sqrt', 'max_leaf_nodes': 4740, 'n_estimators': 283}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:26:20,733]\u001b[0m Trial 74 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 8116, 'max_features': 'sqrt', 'max_leaf_nodes': 4587, 'n_estimators': 289}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:29:01,390]\u001b[0m Trial 75 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 9479, 'max_features': 'auto', 'max_leaf_nodes': 7803, 'n_estimators': 242}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:31:11,568]\u001b[0m Trial 76 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'True', 'max_depth': 9086, 'max_features': 'sqrt', 'max_leaf_nodes': 9313, 'n_estimators': 198}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:34:05,993]\u001b[0m Trial 77 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 7796, 'max_features': 'sqrt', 'max_leaf_nodes': 6357, 'n_estimators': 268}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:37:37,193]\u001b[0m Trial 78 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 6773, 'max_features': 'sqrt', 'max_leaf_nodes': 6075, 'n_estimators': 325}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:42:01,641]\u001b[0m Trial 79 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 7728, 'max_features': 'sqrt', 'max_leaf_nodes': 6647, 'n_estimators': 395}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:42:53,006]\u001b[0m Trial 80 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 9711, 'max_features': 'auto', 'max_leaf_nodes': 8330, 'n_estimators': 73}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:44:43,948]\u001b[0m Trial 81 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'True', 'max_depth': 6205, 'max_features': 'sqrt', 'max_leaf_nodes': 8009, 'n_estimators': 161}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:47:15,956]\u001b[0m Trial 82 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 9286, 'max_features': 'sqrt', 'max_leaf_nodes': 7784, 'n_estimators': 222}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:50:11,977]\u001b[0m Trial 83 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 8885, 'max_features': 'sqrt', 'max_leaf_nodes': 7299, 'n_estimators': 262}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:53:56,843]\u001b[0m Trial 84 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 8509, 'max_features': 'sqrt', 'max_leaf_nodes': 6949, 'n_estimators': 324}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:58:01,157]\u001b[0m Trial 85 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 9729, 'max_features': 'sqrt', 'max_leaf_nodes': 8641, 'n_estimators': 375}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 14:59:48,763]\u001b[0m Trial 86 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'False', 'max_depth': 9113, 'max_features': 'log2', 'max_leaf_nodes': 7474, 'n_estimators': 224}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:01:26,246]\u001b[0m Trial 87 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'True', 'max_depth': 9289, 'max_features': 'sqrt', 'max_leaf_nodes': 7963, 'n_estimators': 142}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:04:34,228]\u001b[0m Trial 88 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 7455, 'max_features': 'auto', 'max_leaf_nodes': 5184, 'n_estimators': 288}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:06:36,601]\u001b[0m Trial 89 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'True', 'max_depth': 7430, 'max_features': 'auto', 'max_leaf_nodes': 5854, 'n_estimators': 188}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:13:03,084]\u001b[0m Trial 90 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 7049, 'max_features': 'auto', 'max_leaf_nodes': 4239, 'n_estimators': 594}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:16:07,448]\u001b[0m Trial 91 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 8154, 'max_features': 'auto', 'max_leaf_nodes': 3729, 'n_estimators': 280}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:18:24,131]\u001b[0m Trial 92 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 456, 'max_features': 'auto', 'max_leaf_nodes': 3183, 'n_estimators': 210}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:21:15,723]\u001b[0m Trial 93 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 8731, 'max_features': 'sqrt', 'max_leaf_nodes': 3669, 'n_estimators': 261}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:24:36,976]\u001b[0m Trial 94 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 402, 'max_features': 'auto', 'max_leaf_nodes': 9823, 'n_estimators': 310}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:28:18,292]\u001b[0m Trial 95 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 9568, 'max_features': 'sqrt', 'max_leaf_nodes': 5034, 'n_estimators': 341}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:30:30,673]\u001b[0m Trial 96 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'True', 'max_depth': 1495, 'max_features': 'sqrt', 'max_leaf_nodes': 9086, 'n_estimators': 204}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:33:18,931]\u001b[0m Trial 97 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 8931, 'max_features': 'sqrt', 'max_leaf_nodes': 7635, 'n_estimators': 246}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:36:07,421]\u001b[0m Trial 98 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'False', 'max_depth': 3523, 'max_features': 'sqrt', 'max_leaf_nodes': 8314, 'n_estimators': 244}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:38:05,830]\u001b[0m Trial 99 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'False', 'max_depth': 4171, 'max_features': 'sqrt', 'max_leaf_nodes': 5603, 'n_estimators': 177}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:41:08,941]\u001b[0m Trial 100 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'False', 'max_depth': 3484, 'max_features': 'sqrt', 'max_leaf_nodes': 6407, 'n_estimators': 274}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:43:42,112]\u001b[0m Trial 101 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'False', 'max_depth': 5063, 'max_features': 'sqrt', 'max_leaf_nodes': 9173, 'n_estimators': 226}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:47:18,266]\u001b[0m Trial 102 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'False', 'max_depth': 8367, 'max_features': 'sqrt', 'max_leaf_nodes': 5357, 'n_estimators': 309}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:49:02,894]\u001b[0m Trial 103 finished with value: 0.7500000000000001 and parameters: {'bootstrap': 'True', 'max_depth': 8737, 'max_features': 'sqrt', 'max_leaf_nodes': 9520, 'n_estimators': 156}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:51:21,114]\u001b[0m Trial 104 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'True', 'max_depth': 7908, 'max_features': 'auto', 'max_leaf_nodes': 5975, 'n_estimators': 198}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:53:13,252]\u001b[0m Trial 105 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 692, 'max_features': 'log2', 'max_leaf_nodes': 7849, 'n_estimators': 237}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:54:18,322]\u001b[0m Trial 106 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'False', 'max_depth': 5535, 'max_features': 'auto', 'max_leaf_nodes': 8959, 'n_estimators': 96}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 15:57:14,430]\u001b[0m Trial 107 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 9464, 'max_features': 'auto', 'max_leaf_nodes': 4847, 'n_estimators': 254}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:06:23,097]\u001b[0m Trial 108 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 9825, 'max_features': 'sqrt', 'max_leaf_nodes': 8076, 'n_estimators': 793}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:10:22,789]\u001b[0m Trial 109 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 8103, 'max_features': 'sqrt', 'max_leaf_nodes': 7812, 'n_estimators': 360}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:13:28,287]\u001b[0m Trial 110 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 9226, 'max_features': 'sqrt', 'max_leaf_nodes': 4474, 'n_estimators': 277}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:16:59,321]\u001b[0m Trial 111 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 9022, 'max_features': 'sqrt', 'max_leaf_nodes': 6789, 'n_estimators': 319}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:19:54,644]\u001b[0m Trial 112 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 8299, 'max_features': 'sqrt', 'max_leaf_nodes': 4217, 'n_estimators': 272}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:22:57,476]\u001b[0m Trial 113 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 8380, 'max_features': 'sqrt', 'max_leaf_nodes': 4606, 'n_estimators': 283}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:26:11,107]\u001b[0m Trial 114 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 8574, 'max_features': 'sqrt', 'max_leaf_nodes': 4799, 'n_estimators': 300}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:28:32,442]\u001b[0m Trial 115 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 8109, 'max_features': 'sqrt', 'max_leaf_nodes': 5592, 'n_estimators': 216}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:30:53,824]\u001b[0m Trial 116 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 8034, 'max_features': 'sqrt', 'max_leaf_nodes': 5787, 'n_estimators': 218}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:34:33,780]\u001b[0m Trial 117 finished with value: 0.746268656716418 and parameters: {'bootstrap': 'True', 'max_depth': 7647, 'max_features': 'auto', 'max_leaf_nodes': 8683, 'n_estimators': 335}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:39:03,041]\u001b[0m Trial 118 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 108, 'max_features': 'auto', 'max_leaf_nodes': 9743, 'n_estimators': 415}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:41:51,007]\u001b[0m Trial 119 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 1100, 'max_features': 'auto', 'max_leaf_nodes': 5139, 'n_estimators': 260}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:43:42,623]\u001b[0m Trial 120 finished with value: 0.7384615384615385 and parameters: {'bootstrap': 'True', 'max_depth': 826, 'max_features': 'auto', 'max_leaf_nodes': 4666, 'n_estimators': 175}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:46:06,733]\u001b[0m Trial 121 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 350, 'max_features': 'auto', 'max_leaf_nodes': 5554, 'n_estimators': 211}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:49:34,961]\u001b[0m Trial 122 finished with value: 0.7575757575757577 and parameters: {'bootstrap': 'True', 'max_depth': 649, 'max_features': 'auto', 'max_leaf_nodes': 5266, 'n_estimators': 295}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n",
            "\u001b[32m[I 2022-02-25 16:52:43,915]\u001b[0m Trial 123 finished with value: 0.7692307692307692 and parameters: {'bootstrap': 'True', 'max_depth': 7926, 'max_features': 'sqrt', 'max_leaf_nodes': 6210, 'n_estimators': 273}. Best is trial 6 with value: 0.7692307692307692.\u001b[0m\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5ba393c8366d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m#Execute optuna and set hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mRF_study\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'maximize'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mRF_study\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRF_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#Create an instance with tuned hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m         )\n\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             )\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-5ba393c8366d>\u001b[0m in \u001b[0;36mRF_objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_slow_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_slow_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0my_slow_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_slow_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_slow_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_slow_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    465\u001b[0m                     \u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_samples_bootstrap\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m                 )\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             )\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 651\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    652\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from pandas.core.common import random_state\n",
        "def RF_objective(trial):\n",
        "    bootstrap = trial.suggest_categorical('bootstrap',['True','False'])\n",
        "    max_depth = trial.suggest_int('max_depth', 1, 10000)\n",
        "    max_features = trial.suggest_categorical('max_features', ['auto', 'sqrt','log2'])\n",
        "    max_leaf_nodes = trial.suggest_int('max_leaf_nodes', 1, 10000)\n",
        "    n_estimators =  trial.suggest_int('n_estimators', 30, 1000)\n",
        "   \n",
        "    model = RandomForestClassifier(bootstrap = bootstrap,\n",
        "                                 max_depth = max_depth, max_features = max_features,\n",
        "                                 max_leaf_nodes = max_leaf_nodes,n_estimators = n_estimators,n_jobs=2,random_state=25)\n",
        "\n",
        "    \n",
        "    model.fit(X_slow_train, y_slow_train)    \n",
        "    y_slow_pred = model.predict(X_slow_test)\n",
        "    f1 = f1_score(y_slow_test, y_slow_pred)\n",
        "  \n",
        "\n",
        "    return f1\n",
        "    \n",
        "#Execute optuna and set hyperparameters\n",
        "RF_study = optuna.create_study(direction='maximize')\n",
        "RF_study.optimize(RF_objective, n_trials=150)\n",
        "\n",
        "#Create an instance with tuned hyperparameters\n",
        "optimized_RF = RandomForestClassifier(max_depth = RF_study.best_params['max_depth'], max_leaf_nodes = RF_study.best_params['max_leaf_nodes'],\n",
        "                                      n_estimators = RF_study.best_params['n_estimators'],n_jobs=2,max_features =RF_study.best_params['max_features'],\n",
        "                                      bootstrap= RF_study.best_params['bootstrap'],random_state=25)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = RandomForestClassifier(random_state=25, n_estimators=251, max_depth=9043, max_leaf_nodes=7310,bootstrap = True, max_features = 'sqrt')\n",
        "model1.fit(X_slow_train, y_slow_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ys9UebdUCGW",
        "outputId": "acbf84ae-85c5-4135-c963-51757acef918"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=9043, max_features='sqrt', max_leaf_nodes=7310,\n",
              "                       n_estimators=251, random_state=25)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU0LAIbkxE3G",
        "outputId": "bd24a14d-7da0-4bf4-b1d2-9124b41f7a82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "train_preds = model1.predict( X_slow_train)\n",
        "f1 = f1_score(train_preds,y_slow_train)\n",
        "f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "MmaXyqV21A93"
      },
      "outputs": [],
      "source": [
        "y_slow_prob = model1.predict_proba(X_slow_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySgXzNaO1CgV",
        "outputId": "b8a65bb9-d432-4d1a-8eeb-3e80b9541415"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n"
          ]
        }
      ],
      "source": [
        "for threshold in range(1,10):\n",
        "    threshold = round(threshold*0.1, 1)\n",
        "    y_slow_pred = np.where(y_slow_prob>=threshold, 1, 0)\n",
        "    print(f'{threshold} :{f1_score(y_slow_test, y_slow_pred[:,1])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tuning 후 feature selection (10~65)"
      ],
      "metadata": {
        "id": "6UqVA2mxUr3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ks = [10,15,20,25,30,35,40,45,50,55,60,65]"
      ],
      "metadata": {
        "id": "eGSgSH-EUriC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### slow\n",
        "* 성능 향상 X"
      ],
      "metadata": {
        "id": "aCxITicnU0_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k in ks:\n",
        "    fit = SelectKBest(chi2, k=k).fit(X_slow_train, y_slow_train)\n",
        "    new_X_slow_train = fit.transform(X_slow_train)\n",
        "    new_X_slow_test = fit.transform(X_slow_test)\n",
        "    \n",
        "    model1.fit(new_X_slow_train, y_slow_train)\n",
        "    y_fast_prob = model1.predict_proba(new_X_slow_test)\n",
        "    print(f'================================{k}================================')\n",
        "    for threshold in range(1,10):\n",
        "        threshold = round(threshold*0.1, 1)\n",
        "        y_slow_pred = np.where(y_slow_prob>=threshold, 1, 0)\n",
        "        print(f'{threshold} :{f1_score(y_slow_test, y_slow_pred[:,1])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hv63h28pUvRr",
        "outputId": "e7dd7563-ec64-4952-c954-99db724e7d5f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================10================================\n",
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n",
            "================================15================================\n",
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n",
            "================================20================================\n",
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n",
            "================================25================================\n",
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n",
            "================================30================================\n",
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n",
            "================================35================================\n",
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n",
            "================================40================================\n",
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n",
            "================================45================================\n",
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n",
            "================================50================================\n",
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n",
            "================================55================================\n",
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n",
            "================================60================================\n",
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n",
            "================================65================================\n",
            "0.1 :0.5045045045045045\n",
            "0.2 :0.6923076923076923\n",
            "0.3 :0.7297297297297297\n",
            "0.4 :0.7123287671232877\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.7540983606557377\n",
            "0.7 :0.7017543859649122\n",
            "0.8 :0.6122448979591837\n",
            "0.9 :0.5333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "급속\n",
        "================================40================================\n",
        "0.4 :0.7169811320754718\n",
        "\n",
        "================================65================================\n",
        "0.4 :0.7169811320754718\n",
        "\n",
        "\n",
        "완속\n",
        "0.5 :0.7692307692307692\n",
        "```\n"
      ],
      "metadata": {
        "id": "4HdjGFtIjxH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HYy-u1WaXjQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "RaKWHwm6XjOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3i17-WirXjLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6EkqEQEYXjJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bUWyvh11XjGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "g0zSpJt8XjDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Mwk5JZuVXjBA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mMKr0s3IXi-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "u4FMkN2tXi7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LightGBM_Optimized"
      ],
      "metadata": {
        "id": "_WEPorQzXmLx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import pandas as pd\n",
        "#import geopandas as gpd\n",
        "import time\n",
        "import json\n",
        "import folium\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "#import fiona\n",
        "#from shapely.geometry.multipolygon import MultiPolygon\n",
        "#from shapely.geometry import Point, Polygon, LineString\n",
        "#from shapely import wkt\n",
        "\n",
        "#from tqdm import trange, tqdm, tqdm_notebook, tnrange\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.preprocessing import Binarizer, MinMaxScaler\n",
        "import sklearn.metrics as metrics\n",
        "from lightgbm import LGBMClassifier\n",
        "import xgboost as xgb\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from functools import partial\n",
        "#from bayes_opt import BayesianOptimization\n",
        "\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "PZOS3sM1XpUh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 50)\n",
        "pd.set_option('display.max_columns', 50)"
      ],
      "metadata": {
        "id": "O-nW5lDQXpPd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_fast_X = train_fast.iloc[:, :-1]\n",
        "train_fast_y = train_fast.iloc[:, -1]\n",
        "test_fast_X = test_fast.iloc[:, :-1]\n",
        "test_fast_y = test_fast.iloc[:, -1]\n",
        "\n",
        "train_slow_X = train_slow.iloc[:, :-1]\n",
        "train_slow_y = train_slow.iloc[:, -1]\n",
        "test_slow_X = test_slow.iloc[:, :-1]\n",
        "test_slow_y = test_slow.iloc[:, -1]"
      ],
      "metadata": {
        "id": "ewzhpAGUYAR4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_clf_fast = LGBMClassifier(n_jobs=-1)\n",
        "lgbm_clf_slow = LGBMClassifier(n_jobs=-1)\n"
      ],
      "metadata": {
        "id": "lxHWkmzGXpMp"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_fast = [lgbm_clf_fast]\n",
        "model_slow = [lgbm_clf_slow]"
      ],
      "metadata": {
        "id": "HJB0c2SeXpKS"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in model_fast:\n",
        "    x.fit(train_fast_X, train_fast_y)\n",
        "for x in model_slow:\n",
        "    x.fit(train_slow_X, train_slow_y)"
      ],
      "metadata": {
        "id": "OeHtj6_fXpHa"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.arange(0,1,0.1)\n",
        "\n",
        "for x in model_fast:\n",
        "    print(x)\n",
        "    pred_proba=x.predict_proba(np.array(test_fast_X))\n",
        "    pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
        "    for threshold in thresholds:\n",
        "        binarizer = Binarizer(threshold=threshold)\n",
        "        model_cl_pred = binarizer.transform(pred_proba_1)\n",
        "        print('threshold : ', threshold)\n",
        "        print('오차 행렬')\n",
        "        confusion = confusion_matrix(test_fast_y,model_cl_pred)\n",
        "        print(confusion)\n",
        "        print('accuracy : ', accuracy_score(test_fast_y,model_cl_pred))\n",
        "        print('precision : ', precision_score(test_fast_y,model_cl_pred))\n",
        "        print('recall : ', recall_score(test_fast_y,model_cl_pred))\n",
        "        print('f1_score : ', f1_score(test_fast_y,model_cl_pred))\n",
        "        print('')\n",
        "    print('===================================================')\n",
        "    print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBWnD5HAXpE7",
        "outputId": "db0f4e66-528b-4240-ed9c-ed7759de5c7a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGBMClassifier()\n",
            "threshold :  0.0\n",
            "오차 행렬\n",
            "[[    0 25550]\n",
            " [    0    25]]\n",
            "accuracy :  0.0009775171065493646\n",
            "precision :  0.0009775171065493646\n",
            "recall :  1.0\n",
            "f1_score :  0.001953125\n",
            "\n",
            "threshold :  0.1\n",
            "오차 행렬\n",
            "[[25534    16]\n",
            " [    6    19]]\n",
            "accuracy :  0.9991397849462366\n",
            "precision :  0.5428571428571428\n",
            "recall :  0.76\n",
            "f1_score :  0.6333333333333332\n",
            "\n",
            "threshold :  0.2\n",
            "오차 행렬\n",
            "[[25536    14]\n",
            " [    7    18]]\n",
            "accuracy :  0.9991788856304985\n",
            "precision :  0.5625\n",
            "recall :  0.72\n",
            "f1_score :  0.631578947368421\n",
            "\n",
            "threshold :  0.30000000000000004\n",
            "오차 행렬\n",
            "[[25539    11]\n",
            " [    8    17]]\n",
            "accuracy :  0.9992570869990225\n",
            "precision :  0.6071428571428571\n",
            "recall :  0.68\n",
            "f1_score :  0.6415094339622641\n",
            "\n",
            "threshold :  0.4\n",
            "오차 행렬\n",
            "[[25540    10]\n",
            " [    8    17]]\n",
            "accuracy :  0.9992961876832844\n",
            "precision :  0.6296296296296297\n",
            "recall :  0.68\n",
            "f1_score :  0.6538461538461539\n",
            "\n",
            "threshold :  0.5\n",
            "오차 행렬\n",
            "[[25543     7]\n",
            " [    9    16]]\n",
            "accuracy :  0.9993743890518084\n",
            "precision :  0.6956521739130435\n",
            "recall :  0.64\n",
            "f1_score :  0.6666666666666666\n",
            "\n",
            "threshold :  0.6000000000000001\n",
            "오차 행렬\n",
            "[[25543     7]\n",
            " [   10    15]]\n",
            "accuracy :  0.9993352883675465\n",
            "precision :  0.6818181818181818\n",
            "recall :  0.6\n",
            "f1_score :  0.6382978723404256\n",
            "\n",
            "threshold :  0.7000000000000001\n",
            "오차 행렬\n",
            "[[25543     7]\n",
            " [   11    14]]\n",
            "accuracy :  0.9992961876832844\n",
            "precision :  0.6666666666666666\n",
            "recall :  0.56\n",
            "f1_score :  0.6086956521739131\n",
            "\n",
            "threshold :  0.8\n",
            "오차 행렬\n",
            "[[25544     6]\n",
            " [   11    14]]\n",
            "accuracy :  0.9993352883675465\n",
            "precision :  0.7\n",
            "recall :  0.56\n",
            "f1_score :  0.6222222222222222\n",
            "\n",
            "threshold :  0.9\n",
            "오차 행렬\n",
            "[[25544     6]\n",
            " [   12    13]]\n",
            "accuracy :  0.9992961876832844\n",
            "precision :  0.6842105263157895\n",
            "recall :  0.52\n",
            "f1_score :  0.5909090909090909\n",
            "\n",
            "===================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = np.arange(0,1,0.1)\n",
        "\n",
        "for x in model_slow:\n",
        "    print(x)\n",
        "    pred_proba=x.predict_proba(np.array(test_slow_X))\n",
        "    pred_proba_1 = pred_proba[:,1].reshape(-1,1)\n",
        "    for threshold in thresholds:\n",
        "        binarizer = Binarizer(threshold=threshold)\n",
        "        model_cl_pred = binarizer.transform(pred_proba_1)\n",
        "        print('threshold : ', threshold)\n",
        "        print('오차 행렬')\n",
        "        confusion = confusion_matrix(test_slow_y,model_cl_pred)\n",
        "        print(confusion)\n",
        "        print('accuracy : ', accuracy_score(test_slow_y,model_cl_pred))\n",
        "        print('precision : ', precision_score(test_slow_y,model_cl_pred))\n",
        "        print('recall : ', recall_score(test_slow_y,model_cl_pred))\n",
        "        print('f1_score : ', f1_score(test_slow_y,model_cl_pred))\n",
        "        print('')\n",
        "    print('===================================================')\n",
        "    print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQOEpnBfXpCL",
        "outputId": "d7a08ef2-45ef-4d51-feb7-3b595cedc71b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LGBMClassifier()\n",
            "threshold :  0.0\n",
            "오차 행렬\n",
            "[[    0 25545]\n",
            " [    0    30]]\n",
            "accuracy :  0.0011730205278592375\n",
            "precision :  0.0011730205278592375\n",
            "recall :  1.0\n",
            "f1_score :  0.0023432923257176333\n",
            "\n",
            "threshold :  0.1\n",
            "오차 행렬\n",
            "[[25520    25]\n",
            " [    1    29]]\n",
            "accuracy :  0.9989833822091887\n",
            "precision :  0.5370370370370371\n",
            "recall :  0.9666666666666667\n",
            "f1_score :  0.6904761904761905\n",
            "\n",
            "threshold :  0.2\n",
            "오차 행렬\n",
            "[[25521    24]\n",
            " [    1    29]]\n",
            "accuracy :  0.9990224828934506\n",
            "precision :  0.5471698113207547\n",
            "recall :  0.9666666666666667\n",
            "f1_score :  0.6987951807228916\n",
            "\n",
            "threshold :  0.30000000000000004\n",
            "오차 행렬\n",
            "[[25523    22]\n",
            " [    1    29]]\n",
            "accuracy :  0.9991006842619746\n",
            "precision :  0.5686274509803921\n",
            "recall :  0.9666666666666667\n",
            "f1_score :  0.7160493827160493\n",
            "\n",
            "threshold :  0.4\n",
            "오차 행렬\n",
            "[[25527    18]\n",
            " [    2    28]]\n",
            "accuracy :  0.9992179863147606\n",
            "precision :  0.6086956521739131\n",
            "recall :  0.9333333333333333\n",
            "f1_score :  0.7368421052631579\n",
            "\n",
            "threshold :  0.5\n",
            "오차 행렬\n",
            "[[25530    15]\n",
            " [    2    28]]\n",
            "accuracy :  0.9993352883675465\n",
            "precision :  0.6511627906976745\n",
            "recall :  0.9333333333333333\n",
            "f1_score :  0.767123287671233\n",
            "\n",
            "threshold :  0.6000000000000001\n",
            "오차 행렬\n",
            "[[25530    15]\n",
            " [    2    28]]\n",
            "accuracy :  0.9993352883675465\n",
            "precision :  0.6511627906976745\n",
            "recall :  0.9333333333333333\n",
            "f1_score :  0.767123287671233\n",
            "\n",
            "threshold :  0.7000000000000001\n",
            "오차 행렬\n",
            "[[25532    13]\n",
            " [    3    27]]\n",
            "accuracy :  0.9993743890518084\n",
            "precision :  0.675\n",
            "recall :  0.9\n",
            "f1_score :  0.7714285714285714\n",
            "\n",
            "threshold :  0.8\n",
            "오차 행렬\n",
            "[[25532    13]\n",
            " [    3    27]]\n",
            "accuracy :  0.9993743890518084\n",
            "precision :  0.675\n",
            "recall :  0.9\n",
            "f1_score :  0.7714285714285714\n",
            "\n",
            "threshold :  0.9\n",
            "오차 행렬\n",
            "[[25536     9]\n",
            " [    5    25]]\n",
            "accuracy :  0.9994525904203324\n",
            "precision :  0.7352941176470589\n",
            "recall :  0.8333333333333334\n",
            "f1_score :  0.78125\n",
            "\n",
            "===================================================\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fea_imp_ = pd.DataFrame({'cols':train_fast_X.columns, 'fea_imp':lgbm_clf_fast.feature_importances_})\n",
        "fea_imp_.sort_values(by=['fea_imp'], ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6TqBuctMYCjE",
        "outputId": "8e0f55c9-40ef-4caf-9931-0811d14c87e5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-377615cb-8c64-4c09-8846-bff02df69a9e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>cols</th>\n",
              "      <th>fea_imp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>dw_lanes_5_scaled</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>up_lanes_5_scaled</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>up_lanes_6_scaled</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>유원지</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>width_5_scaled</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>체력증진시설</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>주거지_scaled</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>급속</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>면적_scaled</td>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>창고_scaled</td>\n",
              "      <td>166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>67 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-377615cb-8c64-4c09-8846-bff02df69a9e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-377615cb-8c64-4c09-8846-bff02df69a9e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-377615cb-8c64-4c09-8846-bff02df69a9e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 cols  fea_imp\n",
              "44  dw_lanes_5_scaled        0\n",
              "42  up_lanes_5_scaled        0\n",
              "41  up_lanes_6_scaled        0\n",
              "62                유원지        0\n",
              "40     width_5_scaled        0\n",
              "..                ...      ...\n",
              "64             체력증진시설       97\n",
              "8          주거지_scaled       98\n",
              "59                 급속      135\n",
              "25          면적_scaled      154\n",
              "5           창고_scaled      166\n",
              "\n",
              "[67 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import optuna\n",
        "from optuna import Trial, visualization\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix"
      ],
      "metadata": {
        "id": "kAheri3OYCgc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_fast_train = train_fast.iloc[:, :-1]\n",
        "y_fast_train = train_fast.iloc[:, -1]\n",
        "X_fast_test = test_fast.iloc[:, :-1]\n",
        "y_fast_test = test_fast.iloc[:, -1]\n",
        "\n",
        "X_slow_train = train_slow.iloc[:, :-1]\n",
        "y_slow_train = train_slow.iloc[:, -1]\n",
        "X_slow_test = test_slow.iloc[:, :-1]\n",
        "y_slow_test = test_slow.iloc[:, -1]"
      ],
      "metadata": {
        "id": "niLniH4nYCag"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'learning_rate': 0.24126919501069777, 'n_estimators': 113, 'max_depth': 31, 'boosting': 'gbdt',\n",
        "         'feature_fraction': 0.8637387162156923, 'scale_pos_weight': 1.6314529692749955, 'num_leaves': 33, 'bagging_freq': 16,\n",
        "         'bagging_fraction': 0.8965246003392066, 'min_data_in_leaf': 890,\n",
        "         'objective':'binary', 'n_jobs':-1, 'random_state':42, 'subsample':1, 'metric':'binary_logloss'}"
      ],
      "metadata": {
        "id": "lXZCJaDbYCXn"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 급속"
      ],
      "metadata": {
        "id": "yfSg2AoQYYZC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_LGBM_f = LGBMClassifier(**param)"
      ],
      "metadata": {
        "id": "-P-YtakHYCUX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_LGBM_f.fit(X_fast_train, y_fast_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cjuVTORYCRa",
        "outputId": "62ce1759-c14f-4857-c7ff-ddd95d79b48c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(bagging_fraction=0.8965246003392066, bagging_freq=16,\n",
              "               boosting='gbdt', feature_fraction=0.8637387162156923,\n",
              "               learning_rate=0.24126919501069777, max_depth=31,\n",
              "               metric='binary_logloss', min_data_in_leaf=890, n_estimators=113,\n",
              "               num_leaves=33, objective='binary', random_state=42,\n",
              "               scale_pos_weight=1.6314529692749955, subsample=1)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_fast_prob = optimized_LGBM_f.predict_proba(X_fast_test)"
      ],
      "metadata": {
        "id": "lJEiWqbVYZ_g"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_fast_pred = optimized_LGBM_f.predict(X_fast_test)\n",
        "f1_score(y_fast_test, y_fast_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lv2K5GlKYZ85",
        "outputId": "59204d1a-2b87-4162-a9ba-d1a871fc5d38"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8000000000000002"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for threshold in range(1,10):\n",
        "    threshold = round(threshold*0.1, 1)\n",
        "    y_fast_pred = np.where(y_fast_prob>=threshold, 1, 0)\n",
        "    print(f'{threshold} :{f1_score(y_fast_test, y_fast_pred[:,1])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkJvnHK_YZ6F",
        "outputId": "5a54159d-14a4-46c4-80cd-83e8871ff6cd"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1 :0.7407407407407408\n",
            "0.2 :0.7843137254901961\n",
            "0.3 :0.7843137254901961\n",
            "0.4 :0.7843137254901961\n",
            "0.5 :0.8000000000000002\n",
            "0.6 :0.7755102040816326\n",
            "0.7 :0.7916666666666667\n",
            "0.8 :0.7916666666666667\n",
            "0.9 :0.7391304347826089\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ks = [30,35,40,45,50,55,60,65]"
      ],
      "metadata": {
        "id": "h_TRjnWUYoud"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in ks:\n",
        "    fit = SelectKBest(chi2, k=k).fit(X_fast_train, y_fast_train)\n",
        "    new_X_fast_train = fit.transform(X_fast_train)\n",
        "    new_X_fast_test = fit.transform(X_fast_test)\n",
        "    \n",
        "    optimized_LGBM_f.fit(new_X_fast_train, y_fast_train)\n",
        "    y_fast_prob = optimized_LGBM_f.predict_proba(new_X_fast_test)\n",
        "    print(f'================================{k}================================')\n",
        "    for threshold in range(1,10):\n",
        "        threshold = round(threshold*0.1, 1)\n",
        "        y_fast_pred = np.where(y_fast_prob>=threshold, 1, 0)\n",
        "        print(f'{threshold} :{f1_score(y_fast_test, y_fast_pred[:,1])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4wKcYzCYrBE",
        "outputId": "ba153172-f957-4cc7-fe48-879b759011c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================10================================\n",
            "0.1 :0.027201145311381535\n",
            "0.2 :0.027377521613832854\n",
            "0.3 :0.3564356435643564\n",
            "0.4 :0.3636363636363637\n",
            "0.5 :0.3655913978494624\n",
            "0.6 :0.40963855421686746\n",
            "0.7 :0.4266666666666667\n",
            "0.8 :0.4444444444444445\n",
            "0.9 :0.4193548387096775\n",
            "================================15================================\n",
            "0.1 :0.6666666666666666\n",
            "0.2 :0.6666666666666666\n",
            "0.3 :0.6909090909090909\n",
            "0.4 :0.7037037037037037\n",
            "0.5 :0.6792452830188679\n",
            "0.6 :0.6923076923076923\n",
            "0.7 :0.6938775510204083\n",
            "0.8 :0.6938775510204083\n",
            "0.9 :0.6666666666666666\n",
            "================================20================================\n",
            "0.1 :0.7037037037037037\n",
            "0.2 :0.7450980392156863\n",
            "0.3 :0.7450980392156863\n",
            "0.4 :0.7346938775510204\n",
            "0.5 :0.7346938775510204\n",
            "0.6 :0.7346938775510204\n",
            "0.7 :0.7346938775510204\n",
            "0.8 :0.7659574468085107\n",
            "0.9 :0.7659574468085107\n",
            "================================25================================\n",
            "0.1 :0.6122448979591836\n",
            "0.2 :0.6122448979591836\n",
            "0.3 :0.6382978723404256\n",
            "0.4 :0.6521739130434783\n",
            "0.5 :0.6521739130434783\n",
            "0.6 :0.6521739130434783\n",
            "0.7 :0.6521739130434783\n",
            "0.8 :0.6818181818181819\n",
            "0.9 :0.6511627906976745\n",
            "================================30================================\n",
            "0.1 :0.7169811320754718\n",
            "0.2 :0.7058823529411765\n",
            "0.3 :0.68\n",
            "0.4 :0.6808510638297872\n",
            "0.5 :0.6956521739130435\n",
            "0.6 :0.6818181818181819\n",
            "0.7 :0.6511627906976745\n",
            "0.8 :0.6511627906976745\n",
            "0.9 :0.6666666666666666\n",
            "================================35================================\n",
            "0.1 :0.7169811320754718\n",
            "0.2 :0.7169811320754718\n",
            "0.3 :0.7169811320754718\n",
            "0.4 :0.7307692307692308\n",
            "0.5 :0.7450980392156863\n",
            "0.6 :0.7450980392156863\n",
            "0.7 :0.7450980392156863\n",
            "0.8 :0.7450980392156863\n",
            "0.9 :0.6666666666666665\n",
            "================================40================================\n",
            "0.1 :0.7037037037037037\n",
            "0.2 :0.7169811320754718\n",
            "0.3 :0.7307692307692308\n",
            "0.4 :0.68\n",
            "0.5 :0.6938775510204083\n",
            "0.6 :0.6521739130434783\n",
            "0.7 :0.6521739130434783\n",
            "0.8 :0.6521739130434783\n",
            "0.9 :0.6521739130434783\n",
            "================================45================================\n",
            "0.1 :0.7307692307692308\n",
            "0.2 :0.7058823529411765\n",
            "0.3 :0.7058823529411765\n",
            "0.4 :0.72\n",
            "0.5 :0.72\n",
            "0.6 :0.72\n",
            "0.7 :0.7083333333333334\n",
            "0.8 :0.6808510638297872\n",
            "0.9 :0.6666666666666665\n",
            "================================50================================\n",
            "0.1 :0.7169811320754718\n",
            "0.2 :0.7450980392156863\n",
            "0.3 :0.7450980392156863\n",
            "0.4 :0.7450980392156863\n",
            "0.5 :0.76\n",
            "0.6 :0.76\n",
            "0.7 :0.76\n",
            "0.8 :0.7499999999999999\n",
            "0.9 :0.7234042553191491\n",
            "================================55================================\n",
            "0.1 :0.7017543859649122\n",
            "0.2 :0.7017543859649122\n",
            "0.3 :0.6909090909090909\n",
            "0.4 :0.7058823529411765\n",
            "0.5 :0.7058823529411765\n",
            "0.6 :0.72\n",
            "0.7 :0.7083333333333334\n",
            "0.8 :0.7111111111111111\n",
            "0.9 :0.7111111111111111\n",
            "================================60================================\n",
            "0.1 :0.03350083752093803\n",
            "0.2 :0.03350083752093803\n",
            "0.3 :0.03350083752093803\n",
            "0.4 :0.03350083752093803\n",
            "0.5 :0.03350083752093803\n",
            "0.6 :0.03350083752093803\n",
            "0.7 :0.03350083752093803\n",
            "0.8 :0.03350083752093803\n",
            "0.9 :0.03350083752093803\n",
            "================================65================================\n",
            "0.1 :0.7692307692307692\n",
            "0.2 :0.7755102040816326\n",
            "0.3 :0.7755102040816326\n",
            "0.4 :0.7755102040816326\n",
            "0.5 :0.7755102040816326\n",
            "0.6 :0.7916666666666667\n",
            "0.7 :0.7916666666666667\n",
            "0.8 :0.7659574468085107\n",
            "0.9 :0.7659574468085107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 최적 score = 0.7169811320754718\n",
        "* 최적 k = 40\n",
        "* 최적 threshold = 0.5, 0.6\n",
        "\n",
        "\n",
        "왜 나는\n",
        "* 최적 score = 0.6 :0.7916666666666667\n",
        "* 최적 k = 65\n",
        "* 최적 threshold = 0.6, 0.7"
      ],
      "metadata": {
        "id": "zRxc91m4lgM_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 완속"
      ],
      "metadata": {
        "id": "IzO-6JkmYePN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param = {'learning_rate': 0.24126919501069777, 'n_estimators': 113, 'max_depth': 31,\n",
        "         'boosting': 'gbdt', 'feature_fraction': 0.8637387162156923, 'scale_pos_weight': 1.6314529692749955,\n",
        "         'num_leaves': 33, 'bagging_freq': 16, 'bagging_fraction': 0.8965246003392066, 'min_data_in_leaf': 890,\n",
        "         'objective':'binary', 'n_jobs':-1, 'random_state':42, 'subsample':1, 'metric':'binary_logloss'}"
      ],
      "metadata": {
        "id": "DruicnR8YZ1T"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_LGBM_s = LGBMClassifier(**param)\n"
      ],
      "metadata": {
        "id": "j_s0id26YZyu"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_LGBM_s.fit(X_slow_train, y_slow_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lT7OYKKgYhKE",
        "outputId": "29e4038b-00b5-4746-f304-ccfb974856d3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LGBMClassifier(bagging_fraction=0.8965246003392066, bagging_freq=16,\n",
              "               boosting='gbdt', feature_fraction=0.8637387162156923,\n",
              "               learning_rate=0.24126919501069777, max_depth=31,\n",
              "               metric='binary_logloss', min_data_in_leaf=890, n_estimators=113,\n",
              "               num_leaves=33, objective='binary', random_state=42,\n",
              "               scale_pos_weight=1.6314529692749955, subsample=1)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_slow_prob = optimized_LGBM_s.predict_proba(X_slow_test)"
      ],
      "metadata": {
        "id": "-iS777q8YhHm"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_slow_pred = optimized_LGBM_s.predict(X_slow_test)\n",
        "f1_score(y_slow_test, y_slow_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ca47UVrYhEg",
        "outputId": "22d476e1-ee62-4a9a-abbe-1c80fb41b708"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.767123287671233"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for threshold in range(1,10):\n",
        "    threshold = round(threshold*0.1, 1)\n",
        "    y_slow_pred = np.where(y_slow_prob>=threshold, 1, 0)\n",
        "    print(f'{threshold} :{f1_score(y_slow_test, y_slow_pred[:,1])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow7FGEDlYmKt",
        "outputId": "144eb98e-01ce-47be-ac9f-13ff5c1f3b0c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1 :0.7435897435897435\n",
            "0.2 :0.7435897435897435\n",
            "0.3 :0.7466666666666667\n",
            "0.4 :0.767123287671233\n",
            "0.5 :0.767123287671233\n",
            "0.6 :0.7777777777777778\n",
            "0.7 :0.7887323943661972\n",
            "0.8 :0.7887323943661972\n",
            "0.9 :0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in ks:\n",
        "    fit = SelectKBest(chi2, k=k).fit(X_slow_train, y_slow_train)\n",
        "    new_X_slow_train = fit.transform(X_slow_train)\n",
        "    new_X_slow_test = fit.transform(X_slow_test)\n",
        "    \n",
        "    optimized_LGBM_s.fit(new_X_slow_train, y_slow_train)\n",
        "    y_slow_prob = optimized_LGBM_s.predict_proba(new_X_slow_test)\n",
        "    print(f'================================{k}================================')\n",
        "    for threshold in range(1,10):\n",
        "        threshold = round(threshold*0.1, 1)\n",
        "        y_slow_pred = np.where(y_slow_prob>=threshold, 1, 0)\n",
        "        print(f'{threshold} :{f1_score(y_slow_test, y_slow_pred[:,1])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UnLorfJwYmIW",
        "outputId": "b48d9e5a-2b92-4596-f3ae-1d4dffa7eaf5"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================30================================\n",
            "0.1 :0.7341772151898733\n",
            "0.2 :0.7200000000000001\n",
            "0.3 :0.7200000000000001\n",
            "0.4 :0.7027027027027029\n",
            "0.5 :0.7323943661971831\n",
            "0.6 :0.7323943661971831\n",
            "0.7 :0.7323943661971831\n",
            "0.8 :0.7536231884057971\n",
            "0.9 :0.7761194029850748\n",
            "================================35================================\n",
            "0.1 :0.6987951807228916\n",
            "0.2 :0.7160493827160493\n",
            "0.3 :0.7012987012987012\n",
            "0.4 :0.7397260273972602\n",
            "0.5 :0.7397260273972602\n",
            "0.6 :0.7397260273972602\n",
            "0.7 :0.7605633802816902\n",
            "0.8 :0.7536231884057971\n",
            "0.9 :0.7761194029850748\n",
            "================================40================================\n",
            "0.1 :0.7341772151898733\n",
            "0.2 :0.7435897435897435\n",
            "0.3 :0.763157894736842\n",
            "0.4 :0.7733333333333334\n",
            "0.5 :0.7733333333333334\n",
            "0.6 :0.7733333333333334\n",
            "0.7 :0.7837837837837838\n",
            "0.8 :0.7887323943661972\n",
            "0.9 :0.8115942028985509\n",
            "================================45================================\n",
            "0.1 :0.7160493827160493\n",
            "0.2 :0.7435897435897435\n",
            "0.3 :0.7532467532467533\n",
            "0.4 :0.763157894736842\n",
            "0.5 :0.7567567567567568\n",
            "0.6 :0.767123287671233\n",
            "0.7 :0.767123287671233\n",
            "0.8 :0.7887323943661972\n",
            "0.9 :0.7647058823529413\n",
            "================================50================================\n",
            "0.1 :0.725\n",
            "0.2 :0.7435897435897435\n",
            "0.3 :0.763157894736842\n",
            "0.4 :0.7466666666666667\n",
            "0.5 :0.7466666666666667\n",
            "0.6 :0.7466666666666667\n",
            "0.7 :0.7567567567567568\n",
            "0.8 :0.767123287671233\n",
            "0.9 :0.8\n",
            "================================55================================\n",
            "0.1 :0.7733333333333334\n",
            "0.2 :0.7733333333333334\n",
            "0.3 :0.7837837837837838\n",
            "0.4 :0.7777777777777778\n",
            "0.5 :0.7777777777777778\n",
            "0.6 :0.8\n",
            "0.7 :0.8\n",
            "0.8 :0.8115942028985509\n",
            "0.9 :0.8059701492537312\n",
            "================================60================================\n",
            "0.1 :0.7532467532467533\n",
            "0.2 :0.7532467532467533\n",
            "0.3 :0.763157894736842\n",
            "0.4 :0.7837837837837838\n",
            "0.5 :0.767123287671233\n",
            "0.6 :0.7887323943661972\n",
            "0.7 :0.7887323943661972\n",
            "0.8 :0.8\n",
            "0.9 :0.8235294117647058\n",
            "================================65================================\n",
            "0.1 :0.7435897435897435\n",
            "0.2 :0.7532467532467533\n",
            "0.3 :0.7532467532467533\n",
            "0.4 :0.7532467532467533\n",
            "0.5 :0.7466666666666667\n",
            "0.6 :0.7567567567567568\n",
            "0.7 :0.767123287671233\n",
            "0.8 :0.8\n",
            "0.9 :0.835820895522388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 최적 score = 0.7945205479452055\n",
        "* 최적 k = 55\n",
        "* 최적 threshold = 0.5\n",
        "\n",
        "왜 나는\n",
        "* 최적 score = 0.835820895522388\n",
        "* 최적 k = 65\n",
        "* 최적 threshold = 0.9"
      ],
      "metadata": {
        "id": "9eIXgvR1lX8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pTtfk1yrYmBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "n6mVBnltYl83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4Vbnt01MYl6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CeSlhvbCa8nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2tmrCjyua8k0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HfhKvOSOa8iB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aekFSRl6a8fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XGBClassifier"
      ],
      "metadata": {
        "id": "wP03yBnqa9JU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "import optuna\n",
        "from optuna import Trial, visualization\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, accuracy_score"
      ],
      "metadata": {
        "id": "t2rxhV2Da8bs"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random # random seed 고정 \n",
        "def set_seeds(seed): \n",
        "    os.environ['PYTHONHASHSEED'] = str(seed) \n",
        "    random.seed(seed) \n",
        "    np.random.seed(seed) \n",
        "    # tf.random.set_seed(seed) # Tensorflow 사용시 \n",
        "    \n",
        "SEED = 555\n",
        "set_seeds(SEED)"
      ],
      "metadata": {
        "id": "7wkB1gwHbCKT"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "XGB = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "              importance_type='gain', interaction_constraints='',\n",
        "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
        "              min_child_weight=1,\n",
        "              n_estimators=100, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
        "              tree_method='exact', validate_parameters=1)\n"
      ],
      "metadata": {
        "id": "ivYe1uhtbGy0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 급속"
      ],
      "metadata": {
        "id": "JIkSqmNubvJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XGB.fit(X_fast_train, y_fast_train)\n",
        "y_fast_prob = XGB.predict_proba(X_fast_test)\n",
        "\n",
        "for threshold in range(1,10):\n",
        "    threshold = round(threshold*0.1, 1)\n",
        "    y_fast_pred = np.where(y_fast_prob>=threshold, 1, 0)\n",
        "    print(f'{threshold} :{f1_score(y_fast_test, y_fast_pred[:,1])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZZPnpe-bGwL",
        "outputId": "956edcc8-e5e8-4371-9f51-8e6a52dd324b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1 :0.6086956521739131\n",
            "0.2 :0.6885245901639344\n",
            "0.3 :0.6909090909090909\n",
            "0.4 :0.7037037037037037\n",
            "0.5 :0.6923076923076923\n",
            "0.6 :0.6666666666666666\n",
            "0.7 :0.6956521739130435\n",
            "0.8 :0.6666666666666665\n",
            "0.9 :0.6666666666666665\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ks = [10,15,20,25,30,35,40,45,50,55,60,65]            # ## tuning 후 feature selection (10~65)"
      ],
      "metadata": {
        "id": "69mPVN8Cbz3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in ks:\n",
        "    fit = SelectKBest(chi2, k=k).fit(X_fast_train, y_fast_train)\n",
        "    new_X_fast_train = fit.transform(X_fast_train)\n",
        "    new_X_fast_test = fit.transform(X_fast_test)\n",
        "    \n",
        "    XGB.fit(new_X_fast_train, y_fast_train)\n",
        "    y_fast_prob = XGB.predict_proba(new_X_fast_test)\n",
        "    print(f'================================{k}================================')\n",
        "    for threshold in range(1,10):\n",
        "        threshold = round(threshold*0.1, 1)\n",
        "        y_fast_pred = np.where(y_fast_prob>=threshold, 1, 0)\n",
        "        print(f'{threshold} :{f1_score(y_fast_test, y_fast_pred[:,1])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvUGQvqpbz07",
        "outputId": "9c24e95b-3ad3-480c-e8a4-651258628763"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================10================================\n",
            "0.1 :0.027027027027027025\n",
            "0.2 :0.43902439024390244\n",
            "0.3 :0.5070422535211268\n",
            "0.4 :0.5964912280701754\n",
            "0.5 :0.6071428571428571\n",
            "0.6 :0.6296296296296295\n",
            "0.7 :0.5882352941176471\n",
            "0.8 :0.5531914893617023\n",
            "0.9 :0.5652173913043478\n",
            "================================15================================\n",
            "0.1 :0.5185185185185186\n",
            "0.2 :0.6060606060606061\n",
            "0.3 :0.6440677966101696\n",
            "0.4 :0.6206896551724138\n",
            "0.5 :0.576923076923077\n",
            "0.6 :0.5490196078431373\n",
            "0.7 :0.5416666666666667\n",
            "0.8 :0.5531914893617023\n",
            "0.9 :0.5454545454545454\n",
            "================================20================================\n",
            "0.1 :0.5633802816901409\n",
            "0.2 :0.5806451612903226\n",
            "0.3 :0.6428571428571428\n",
            "0.4 :0.6792452830188679\n",
            "0.5 :0.6538461538461539\n",
            "0.6 :0.68\n",
            "0.7 :0.7083333333333334\n",
            "0.8 :0.6521739130434783\n",
            "0.9 :0.5853658536585366\n",
            "================================25================================\n",
            "0.1 :0.6349206349206348\n",
            "0.2 :0.6666666666666666\n",
            "0.3 :0.7058823529411765\n",
            "0.4 :0.72\n",
            "0.5 :0.7346938775510204\n",
            "0.6 :0.7346938775510204\n",
            "0.7 :0.7346938775510204\n",
            "0.8 :0.7391304347826089\n",
            "0.9 :0.7111111111111111\n",
            "================================30================================\n",
            "0.1 :0.6557377049180328\n",
            "0.2 :0.7272727272727272\n",
            "0.3 :0.7547169811320756\n",
            "0.4 :0.7692307692307692\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.76\n",
            "0.7 :0.76\n",
            "0.8 :0.6808510638297872\n",
            "0.9 :0.6818181818181819\n",
            "================================35================================\n",
            "0.1 :0.6268656716417911\n",
            "0.2 :0.711864406779661\n",
            "0.3 :0.7777777777777777\n",
            "0.4 :0.7307692307692308\n",
            "0.5 :0.7450980392156863\n",
            "0.6 :0.6938775510204083\n",
            "0.7 :0.7083333333333334\n",
            "0.8 :0.7083333333333334\n",
            "0.9 :0.6808510638297872\n",
            "================================40================================\n",
            "0.1 :0.6176470588235294\n",
            "0.2 :0.711864406779661\n",
            "0.3 :0.7142857142857142\n",
            "0.4 :0.6909090909090909\n",
            "0.5 :0.6530612244897959\n",
            "0.6 :0.6666666666666666\n",
            "0.7 :0.6666666666666666\n",
            "0.8 :0.6382978723404256\n",
            "0.9 :0.6086956521739131\n",
            "================================45================================\n",
            "0.1 :0.6461538461538462\n",
            "0.2 :0.736842105263158\n",
            "0.3 :0.75\n",
            "0.4 :0.7169811320754718\n",
            "0.5 :0.72\n",
            "0.6 :0.6938775510204083\n",
            "0.7 :0.6938775510204083\n",
            "0.8 :0.6808510638297872\n",
            "0.9 :0.6818181818181819\n",
            "================================50================================\n",
            "0.1 :0.6562499999999999\n",
            "0.2 :0.7000000000000001\n",
            "0.3 :0.736842105263158\n",
            "0.4 :0.75\n",
            "0.5 :0.7407407407407408\n",
            "0.6 :0.7307692307692308\n",
            "0.7 :0.7450980392156863\n",
            "0.8 :0.6938775510204083\n",
            "0.9 :0.6222222222222222\n",
            "================================55================================\n",
            "0.1 :0.6461538461538462\n",
            "0.2 :0.6774193548387097\n",
            "0.3 :0.6551724137931034\n",
            "0.4 :0.6666666666666666\n",
            "0.5 :0.6909090909090909\n",
            "0.6 :0.7169811320754718\n",
            "0.7 :0.68\n",
            "0.8 :0.6938775510204083\n",
            "0.9 :0.6956521739130435\n",
            "================================60================================\n",
            "0.1 :0.6461538461538462\n",
            "0.2 :0.6885245901639344\n",
            "0.3 :0.75\n",
            "0.4 :0.7777777777777777\n",
            "0.5 :0.7692307692307692\n",
            "0.6 :0.76\n",
            "0.7 :0.76\n",
            "0.8 :0.7083333333333334\n",
            "0.9 :0.7083333333333334\n",
            "================================65================================\n",
            "0.1 :0.6176470588235294\n",
            "0.2 :0.7000000000000001\n",
            "0.3 :0.736842105263158\n",
            "0.4 :0.7407407407407408\n",
            "0.5 :0.7058823529411765\n",
            "0.6 :0.72\n",
            "0.7 :0.6938775510204083\n",
            "0.8 :0.6666666666666666\n",
            "0.9 :0.6808510638297872\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 60\n",
        "- 0.4 :0.7777777777777777"
      ],
      "metadata": {
        "id": "4yG6arALP2B0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "f6jBfN8RbzwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GIhJIXcwbztS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 완속"
      ],
      "metadata": {
        "id": "NQUx3pUub0Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XGB.fit(X_slow_train, y_slow_train)\n",
        "y_slow_prob = XGB.predict_proba(X_slow_test)\n",
        "\n",
        "for threshold in range(1,10):\n",
        "    threshold = round(threshold*0.1, 1)\n",
        "    y_slow_pred = np.where(y_slow_prob>=threshold, 1, 0)\n",
        "    print(f'{threshold} :{f1_score(y_slow_test, y_slow_pred[:,1])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKGuIWa8b1jK",
        "outputId": "a6e6846f-39ae-4bda-d950-d0f8c0238264"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.1 :0.6451612903225806\n",
            "0.2 :0.6976744186046512\n",
            "0.3 :0.6904761904761905\n",
            "0.4 :0.7160493827160493\n",
            "0.5 :0.7272727272727273\n",
            "0.6 :0.767123287671233\n",
            "0.7 :0.7714285714285714\n",
            "0.8 :0.7575757575757577\n",
            "0.9 :0.7419354838709677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k in ks:\n",
        "    fit = SelectKBest(chi2, k=k).fit(X_slow_train, y_slow_train)\n",
        "    new_X_slow_train = fit.transform(X_slow_train)\n",
        "    new_X_slow_test = fit.transform(X_slow_test)\n",
        "    \n",
        "    XGB.fit(new_X_slow_train, y_slow_train)\n",
        "    y_slow_prob = XGB.predict_proba(new_X_slow_test)\n",
        "    print(f'================================{k}================================')\n",
        "    for threshold in range(1,10):\n",
        "        threshold = round(threshold*0.1, 1)\n",
        "        y_slow_pred = np.where(y_slow_prob>=threshold, 1, 0)\n",
        "        print(f'{threshold} :{f1_score(y_slow_test, y_slow_pred[:,1])}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4cgH0kGb1gD",
        "outputId": "a5976c2c-1030-4676-d992-c1a24b8b6616"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================30================================\n",
            "0.1 :0.5742574257425742\n",
            "0.2 :0.5977011494252873\n",
            "0.3 :0.6190476190476191\n",
            "0.4 :0.6419753086419753\n",
            "0.5 :0.65\n",
            "0.6 :0.6133333333333334\n",
            "0.7 :0.6197183098591549\n",
            "0.8 :0.6470588235294117\n",
            "0.9 :0.65625\n",
            "================================35================================\n",
            "0.1 :0.5742574257425742\n",
            "0.2 :0.6236559139784946\n",
            "0.3 :0.6428571428571429\n",
            "0.4 :0.6419753086419753\n",
            "0.5 :0.6666666666666667\n",
            "0.6 :0.6666666666666667\n",
            "0.7 :0.676056338028169\n",
            "0.8 :0.6857142857142857\n",
            "0.9 :0.6769230769230768\n",
            "================================40================================\n",
            "0.1 :0.5858585858585859\n",
            "0.2 :0.6292134831460674\n",
            "0.3 :0.6588235294117647\n",
            "0.4 :0.6913580246913581\n",
            "0.5 :0.7088607594936709\n",
            "0.6 :0.7105263157894737\n",
            "0.7 :0.676056338028169\n",
            "0.8 :0.6666666666666667\n",
            "0.9 :0.696969696969697\n",
            "================================45================================\n",
            "0.1 :0.6451612903225806\n",
            "0.2 :0.6590909090909091\n",
            "0.3 :0.6744186046511628\n",
            "0.4 :0.725\n",
            "0.5 :0.7435897435897435\n",
            "0.6 :0.6756756756756758\n",
            "0.7 :0.676056338028169\n",
            "0.8 :0.6857142857142857\n",
            "0.9 :0.6769230769230768\n",
            "================================50================================\n",
            "0.1 :0.6060606060606061\n",
            "0.2 :0.6444444444444445\n",
            "0.3 :0.7073170731707317\n",
            "0.4 :0.7088607594936709\n",
            "0.5 :0.7012987012987012\n",
            "0.6 :0.6842105263157895\n",
            "0.7 :0.684931506849315\n",
            "0.8 :0.7042253521126761\n",
            "0.9 :0.6865671641791045\n",
            "================================55================================\n",
            "0.1 :0.5800000000000001\n",
            "0.2 :0.6666666666666667\n",
            "0.3 :0.6904761904761905\n",
            "0.4 :0.725\n",
            "0.5 :0.7466666666666667\n",
            "0.6 :0.7567567567567568\n",
            "0.7 :0.7826086956521738\n",
            "0.8 :0.7647058823529413\n",
            "0.9 :0.7384615384615385\n",
            "================================60================================\n",
            "0.1 :0.6593406593406593\n",
            "0.2 :0.7160493827160493\n",
            "0.3 :0.725\n",
            "0.4 :0.7435897435897435\n",
            "0.5 :0.7272727272727273\n",
            "0.6 :0.7200000000000001\n",
            "0.7 :0.7123287671232877\n",
            "0.8 :0.7142857142857143\n",
            "0.9 :0.7272727272727272\n",
            "================================65================================\n",
            "0.1 :0.6451612903225806\n",
            "0.2 :0.7142857142857143\n",
            "0.3 :0.7160493827160493\n",
            "0.4 :0.7160493827160493\n",
            "0.5 :0.7435897435897435\n",
            "0.6 :0.7368421052631579\n",
            "0.7 :0.7428571428571429\n",
            "0.8 :0.746268656716418\n",
            "0.9 :0.7936507936507938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 65\n",
        "- 0.9 :0.7936507936507938"
      ],
      "metadata": {
        "id": "XtuCwgE3QJiF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "q8wjoSz8b1dA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nPFbqfNfb0-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YVrABkDTrAOG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6J5rjuiwrALC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cYzRuYFrrAH4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 앙상블\n",
        "## 1) Voting"
      ],
      "metadata": {
        "id": "cN4acPkzrD2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, ExtraTreesClassifier, BaggingClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegressionCV, RidgeClassifier\n",
        "# VotingClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "A3lB4_ULrAEW"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_fast_X = train_fast.iloc[:, :-1]\n",
        "train_fast_y = train_fast.iloc[:, -1]\n",
        "test_fast_X = test_fast.iloc[:, :-1]\n",
        "test_fast_y = test_fast.iloc[:, -1]\n",
        "\n",
        "train_slow_X = train_slow.iloc[:, :-1]\n",
        "train_slow_y = train_slow.iloc[:, -1]\n",
        "test_slow_X = test_slow.iloc[:, :-1]\n",
        "test_slow_y = test_slow.iloc[:, -1]"
      ],
      "metadata": {
        "id": "pj7Opi9tsJPT"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#VotingClassifier \n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "soft_vote = VotingClassifier(estimators=[('rfc', model),\n",
        "    ('lgbm', optimized_LGBM_f),\n",
        "    ('xgb',XGB) ], voting='soft')"
      ],
      "metadata": {
        "id": "2-wdnE2EXktk"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soft_vote.fit(train_fast_X,train_fast_y)\n",
        "soft_vote.score(test_fast_X,test_fast_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hj0NoOx65Pup",
        "outputId": "a4fee6b8-beff-4826-fbfc-b13bd7f15125"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9995698924731182"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 급속 soft voting"
      ],
      "metadata": {
        "id": "-xG9wPeyZmvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 비교\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "for models in (model,optimized_LGBM_f, XGB, soft_vote):\n",
        "  models.fit(train_fast_X,train_fast_y)\n",
        "  y_pred = models.predict(test_fast_X)\n",
        "  print(models.__class__.__name__,\" : \",accuracy_score(test_fast_y,y_pred))\n",
        "  \n",
        "\n",
        "  f1 = f1_score(test_fast_y, y_pred)\n",
        "  print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZIww46W6IVT",
        "outputId": "2a2697cf-2e3f-459a-fb09-ed14dc4a966b"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier  :  0.9994134897360704\n",
            "0.6666666666666665\n",
            "LGBMClassifier  :  0.9996089931573803\n",
            "0.8000000000000002\n",
            "XGBClassifier  :  0.9993743890518084\n",
            "0.6923076923076923\n",
            "VotingClassifier  :  0.9995698924731182\n",
            "0.7755102040816326\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 완속 soft voting"
      ],
      "metadata": {
        "id": "dEsf-aO1Zq1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VotingClassifier \n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "soft_vote_slow = VotingClassifier(estimators=[('rfc', model1),\n",
        "    ('lgbm', optimized_LGBM_s),\n",
        "    ('xgb',XGB) ], voting='soft')"
      ],
      "metadata": {
        "id": "Mkh3Wg2gYafl"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "soft_vote_slow.fit(train_slow_X,train_slow_y)\n",
        "soft_vote_slow.score(test_slow_X,test_slow_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnucBXjWbzPz",
        "outputId": "e2a004bb-a950-4a57-f8f6-deb2778fc872"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9992961876832844"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 비교\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "for models in (model1,optimized_LGBM_s, XGB, soft_vote_slow):\n",
        "  models.fit(train_slow_X,train_slow_y)\n",
        "  y_pred = models.predict(test_slow_X)\n",
        "  print(models.__class__.__name__,\" : \",accuracy_score(test_slow_y,y_pred))\n",
        "  \n",
        "\n",
        "  f1 = f1_score(test_slow_y, y_pred)\n",
        "  print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGVKoGMCYaXI",
        "outputId": "c9d6d1af-1c0a-4691-cb73-c3ccdf76bbf1"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier  :  0.9994134897360704\n",
            "0.7692307692307692\n",
            "LGBMClassifier  :  0.9993352883675465\n",
            "0.767123287671233\n",
            "XGBClassifier  :  0.9991788856304985\n",
            "0.7272727272727273\n",
            "VotingClassifier  :  0.9992961876832844\n",
            "0.7567567567567568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EvJmdF4lZsvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "8Xjwu9xuZssh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "W0n5IZIrcHga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GlbbthpFcHdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 급속 hard voting"
      ],
      "metadata": {
        "id": "O7JxHHaNZtAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VotingClassifier \n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "hard_vote_fast = VotingClassifier(estimators=[('rfc', model),\n",
        "    ('lgbm', optimized_LGBM_f),\n",
        "    ('xgb',XGB) ], voting='hard')"
      ],
      "metadata": {
        "id": "CsHVBYlaZsqB"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hard_vote_fast.fit(train_fast_X,train_fast_y)\n",
        "hard_vote_fast.score(test_fast_X,test_fast_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nH3PjHDX5kcI",
        "outputId": "7cda317f-ced1-45b2-cc2a-f921b645d994"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9994916911045943"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 비교\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "for models in (model,optimized_LGBM_f, XGB, hard_vote_fast):\n",
        "  models.fit(train_fast_X,train_fast_y)\n",
        "  y_pred = models.predict(test_fast_X)\n",
        "  print(models.__class__.__name__,\" : \",accuracy_score(test_fast_y,y_pred))\n",
        "\n",
        "  f1 = f1_score(test_fast_y, y_pred)\n",
        "  print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYiawaWA6zU6",
        "outputId": "c7d4b3f0-3ad7-462f-da82-a36ea04cb5b9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier  :  0.9994134897360704\n",
            "0.6666666666666665\n",
            "LGBMClassifier  :  0.9996089931573803\n",
            "0.8000000000000002\n",
            "XGBClassifier  :  0.9993743890518084\n",
            "0.6923076923076923\n",
            "VotingClassifier  :  0.9994916911045943\n",
            "0.7346938775510204\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 완속 hard voting"
      ],
      "metadata": {
        "id": "X21U1DmcZwlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#VotingClassifier \n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "hard_vote_slow = VotingClassifier(estimators=[('rfc', model1),\n",
        "    ('lgbm', optimized_LGBM_s),\n",
        "    ('xgb',XGB) ], voting='hard')"
      ],
      "metadata": {
        "id": "fJgp3vSo5xbO"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hard_vote_slow.fit(train_slow_X,train_slow_y)\n",
        "hard_vote_slow.score(test_slow_X,test_slow_y)"
      ],
      "metadata": {
        "id": "HtmdQT6Z5xXg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2ed69a0-2871-4cf7-8177-80470f2385e1"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9993352883675465"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 비교\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "for models in (model1,optimized_LGBM_s, XGB, hard_vote_slow):\n",
        "  models.fit(train_slow_X,train_slow_y)\n",
        "  y_pred = models.predict(test_slow_X)\n",
        "  print(models.__class__.__name__,\" : \",accuracy_score(test_slow_y,y_pred))\n",
        "\n",
        "  f1 = f1_score(test_slow_y, y_pred)\n",
        "  print(f1)"
      ],
      "metadata": {
        "id": "mtjCPYZ93jT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94be461c-21f9-4b7d-a21b-069cb090704a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForestClassifier  :  0.9994134897360704\n",
            "0.7692307692307692\n",
            "LGBMClassifier  :  0.9993352883675465\n",
            "0.767123287671233\n",
            "XGBClassifier  :  0.9991788856304985\n",
            "0.7272727272727273\n",
            "VotingClassifier  :  0.9993352883675465\n",
            "0.767123287671233\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "pFW87HCV3jMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "w2QLLfoXkOmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D4NVLpPbkOjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gC5PbbeGkOg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sbHNjkmFxIUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) baggingclassifier"
      ],
      "metadata": {
        "id": "3-xRE2NPxJmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "# 모델 구축\n",
        "# BaggingClassifier에서 사용한 분류기가 클래스 확률추정(predict_proba)이 가능하면 자동으로 간접 투표 사용 \n",
        "bag_model = BaggingClassifier(\n",
        "    RandomForestClassifier(random_state=25, n_estimators=31, max_depth=2699, max_leaf_nodes=172,bootstrap = True, max_features = 'auto'),\n",
        "    n_estimators=500, # 약한 학습기(결정 트리) 500개 생성\n",
        "    max_samples=0.05, # 0.0~1.0 사이 실수 선택(실수 x 샘플 수) 혹은 샘플수 지정\n",
        "    bootstrap=True, # True : 배깅, False : 페이스팅\n",
        "    n_jobs=-1 # 훈련과 예측에 사용할 CPU 코어 수 (-1 : 가용한 모든 코어 사용)\n",
        ")\n"
      ],
      "metadata": {
        "id": "do1sqkAIxIQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 모델 학습\n",
        "bag_model.fit(train_fast_X,train_fast_y)\n",
        "\n",
        "# 모델 예측\n",
        "y_pred = bag_model.predict(test_fast_X)\n",
        "\n",
        "# 모델 평가\n",
        "print(bag_model.__class__.__name__,\" : \",accuracy_score(test_fast_y,y_pred))\n",
        "\n",
        "f1 = f1_score(test_fast_y, y_pred)\n",
        "print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "otBgHXAJxINe",
        "outputId": "694c657b-5b06-45fe-db8f-929a621a8560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaggingClassifier  :  0.9942521994134897\n",
            "0.2054054054054054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "# 모델 구축\n",
        "# BaggingClassifier에서 사용한 분류기가 클래스 확률추정(predict_proba)이 가능하면 자동으로 간접 투표 사용 \n",
        "bag_model1 = BaggingClassifier(\n",
        "    XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
        "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
        "              importance_type='gain', interaction_constraints='',\n",
        "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
        "              min_child_weight=1,\n",
        "              n_estimators=100, n_jobs=-1, num_parallel_tree=1, random_state=42,\n",
        "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
        "              tree_method='exact', validate_parameters=1),\n",
        "    bootstrap=True, # True : 배깅, False : 페이스팅\n",
        "    n_jobs=-1 # 훈련과 예측에 사용할 CPU 코어 수 (-1 : 가용한 모든 코어 사용)\n",
        ")\n",
        "\n",
        "\n",
        "# 모델 학습\n",
        "bag_model1.fit(train_fast_X,train_fast_y)\n",
        "\n",
        "# 모델 예측\n",
        "y_pred = bag_model1.predict(test_fast_X)\n",
        "\n",
        "# 모델 평가\n",
        "print(bag_model1.__class__.__name__,\" : \",accuracy_score(test_fast_y,y_pred))\n",
        "\n",
        "f1 = f1_score(test_fast_y, y_pred)\n",
        "print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-STmLn69vcL",
        "outputId": "46e20118-ce39-4408-80ed-695cbab37bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaggingClassifier  :  0.9993743890518084\n",
            "0.7142857142857142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "# 모델 구축\n",
        "# BaggingClassifier에서 사용한 분류기가 클래스 확률추정(predict_proba)이 가능하면 자동으로 간접 투표 사용 \n",
        "bag_model2 = BaggingClassifier(\n",
        "    LGBMClassifier(n_jobs=-1),\n",
        "\n",
        "    bootstrap=True, # True : 배깅, False : 페이스팅\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "# 모델 학습\n",
        "bag_model2.fit(train_fast_X,train_fast_y)\n",
        "\n",
        "# 모델 예측\n",
        "y_pred = bag_model2.predict(test_fast_X)\n",
        "\n",
        "# 모델 평가\n",
        "print(bag_model2.__class__.__name__,\" : \",accuracy_score(test_fast_y,y_pred))\n",
        "\n",
        "f1 = f1_score(test_fast_y, y_pred)\n",
        "print(f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0i2fE84_5MV",
        "outputId": "46faeb90-42d3-44b4-e07e-92608a11f07d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaggingClassifier  :  0.9992961876832844\n",
            "0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2IlQMSmZ_5Dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FMudJV7f_45I"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "모델3개다같이voting.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}