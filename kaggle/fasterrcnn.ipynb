{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm # progress bar\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor, FasterRCNN\n",
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from glob import glob\n",
    "import numba\n",
    "import re\n",
    "from numba import jit\n",
    "from PIL import Image\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>boxes</th>\n",
       "      <th>label</th>\n",
       "      <th>StudyInstanceUID</th>\n",
       "      <th>class</th>\n",
       "      <th>filename</th>\n",
       "      <th>dim0</th>\n",
       "      <th>dim1</th>\n",
       "      <th>split</th>\n",
       "      <th>xyxy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000a312787f2_image</td>\n",
       "      <td>[{'x': 789.28836, 'y': 582.43035, 'width': 102...</td>\n",
       "      <td>opacity 1 789.28836 582.43035 1815.94498 2499....</td>\n",
       "      <td>5776db0cec75</td>\n",
       "      <td>opacity</td>\n",
       "      <td>000a312787f2</td>\n",
       "      <td>3488</td>\n",
       "      <td>4256</td>\n",
       "      <td>train</td>\n",
       "      <td>[[47, 42, 109, 183], [135, 43, 200, 172]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c3a3f293f_image</td>\n",
       "      <td>NaN</td>\n",
       "      <td>none 1 0 0 1 1</td>\n",
       "      <td>ff0879eb20ed</td>\n",
       "      <td>none</td>\n",
       "      <td>000c3a3f293f</td>\n",
       "      <td>2320</td>\n",
       "      <td>2832</td>\n",
       "      <td>train</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0012ff7358bc_image</td>\n",
       "      <td>[{'x': 677.42216, 'y': 197.97662, 'width': 867...</td>\n",
       "      <td>opacity 1 677.42216 197.97662 1545.21983 1197....</td>\n",
       "      <td>9d514ce429a7</td>\n",
       "      <td>opacity</td>\n",
       "      <td>0012ff7358bc</td>\n",
       "      <td>2544</td>\n",
       "      <td>3056</td>\n",
       "      <td>train</td>\n",
       "      <td>[[56, 19, 129, 120], [150, 40, 201, 161]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                              boxes  \\\n",
       "0  000a312787f2_image  [{'x': 789.28836, 'y': 582.43035, 'width': 102...   \n",
       "1  000c3a3f293f_image                                                NaN   \n",
       "2  0012ff7358bc_image  [{'x': 677.42216, 'y': 197.97662, 'width': 867...   \n",
       "\n",
       "                                               label StudyInstanceUID  \\\n",
       "0  opacity 1 789.28836 582.43035 1815.94498 2499....     5776db0cec75   \n",
       "1                                     none 1 0 0 1 1     ff0879eb20ed   \n",
       "2  opacity 1 677.42216 197.97662 1545.21983 1197....     9d514ce429a7   \n",
       "\n",
       "     class      filename  dim0  dim1  split  \\\n",
       "0  opacity  000a312787f2  3488  4256  train   \n",
       "1     none  000c3a3f293f  2320  2832  train   \n",
       "2  opacity  0012ff7358bc  2544  3056  train   \n",
       "\n",
       "                                        xyxy  \n",
       "0  [[47, 42, 109, 183], [135, 43, 200, 172]]  \n",
       "1                                       None  \n",
       "2  [[56, 19, 129, 120], [150, 40, 201, 161]]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_bbox(row):\n",
    "    bboxes = []\n",
    "    bbox = []\n",
    "    for i, l in enumerate(row.label.split(' ')):\n",
    "        if (i % 6 == 0) | (i % 6 == 1):\n",
    "            continue\n",
    "        bbox.append(float(l))\n",
    "        if i % 6 == 5:\n",
    "            bboxes.append(bbox)\n",
    "            bbox = []  \n",
    "            \n",
    "    return bboxes\n",
    "    \n",
    "\n",
    "def scale_box(row):\n",
    "    if row['class'] == 'opacity':\n",
    "        scale_x = 256/row.dim1\n",
    "        scale_y = 256/row.dim0\n",
    "\n",
    "        scaled_boxes = []\n",
    "        for box in row.xyxy:\n",
    "            x = int(np.round(box[0]*scale_x, 4))\n",
    "            y = int(np.round(box[1]*scale_y, 4))\n",
    "            w = int(np.round(box[2]*(scale_x), 4))\n",
    "            h = int(np.round(box[3]*scale_y, 4))\n",
    "            scaled_boxes.append([x, y, w, h])\n",
    "\n",
    "        return scaled_boxes\n",
    "\n",
    "df = pd.read_csv('train_image_level.csv')\n",
    "df['class'] = df.apply(lambda row: row.label.split(' ')[0], axis=1)\n",
    "df['filename'] = df.apply(lambda row: row.id[:-6], axis=1)\n",
    "\n",
    "meta = pd.read_csv('meta.csv')\n",
    "meta.columns = ['filename', 'dim0', 'dim1', 'split']\n",
    "\n",
    "df = df.merge(meta, on='filename', how='left')\n",
    "\n",
    "df['xyxy'] = df.apply(get_bbox, axis=1)\n",
    "df['xyxy'] = df.apply(scale_box, axis=1)\n",
    "# df.drop(columns=['split'], inplace=True)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4294, 2040)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opacity = {}\n",
    "none = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    name = row.filename\n",
    "    if row['class'] == 'opacity':\n",
    "        opacity[name]= row.xyxy\n",
    "    else:\n",
    "        none.append(name)\n",
    "        \n",
    "len(opacity), len(none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10306, 2040)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_competition_df = pd.read_csv('rsna-pneumonia/stage_2_train_labels.csv')\n",
    "\n",
    "extract_box = lambda row: [i*256/1024 for i in [row['x'], row['y'], row['x']+row['width'], row['y']+row['height']]]\n",
    "\n",
    "for index, row in old_competition_df.iterrows():\n",
    "    pid = row['patientId']\n",
    "    if row.Target == 1:\n",
    "        if pid not in opacity:\n",
    "            opacity[pid] = []\n",
    "        opacity[pid].append(extract_box(row))\n",
    "    ''' want less negative samples\n",
    "    else:\n",
    "        if none[-1] != pid:\n",
    "            none.append(pid)\n",
    "    '''\n",
    "            \n",
    "len(opacity), len(none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8244, 2062)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = opacity.copy()\n",
    "\n",
    "'''\n",
    "for name in none:\n",
    "    data[name] = None\n",
    "'''\n",
    "    \n",
    "train, valid  = [i.to_dict() for i in train_test_split(pd.Series(data), train_size=0.8, random_state=42)]\n",
    "\n",
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LungDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.all_names, self.all_boxes = zip(*data.items())\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        name = self.all_names[index]\n",
    "        boxes = self.all_boxes[index]\n",
    "        \n",
    "        if '-' in name:\n",
    "            img = cv2.imread(f'../input/rsna-256/{name}.png', 0)\n",
    "        else:\n",
    "            img = cv2.imread(f'../input/siim-covid19-resized-to-256px-png/train/{name}.png', 0)\n",
    "                \n",
    "        if boxes != None:\n",
    "            transform = A.Compose([\n",
    "                A.HorizontalFlip(p=.5),\n",
    "                A.RandomGamma(p=1),\n",
    "                A.ShiftScaleRotate(rotate_limit=10, p=.5),\n",
    "                A.Cutout(p=.3),\n",
    "                A.RandomBrightness(p=.5),\n",
    "                ToTensorV2()\n",
    "            ], bbox_params=A.BboxParams(format='pascal_voc', label_fields=[]))\n",
    "            \n",
    "            sample = transform(image=img, bboxes=boxes)\n",
    "\n",
    "            tmp = np.array(sample['bboxes'])\n",
    "            \n",
    "            assert np.all(tmp[:, 3]>tmp[:, 1]) & np.all(tmp[:, 2]>tmp[:, 0])\n",
    "          \n",
    "            target = {\"boxes\": torch.as_tensor(sample['bboxes'], dtype=torch.float32),\n",
    "                      \"labels\": torch.ones((len(boxes)), dtype=torch.int64),\n",
    "                      \"image_id\": torch.tensor([index]),\n",
    "                      \"area\": torch.as_tensor((tmp[:,2]-tmp[:,0])*(tmp[:,3]-tmp[:,1]), dtype=torch.float32),\n",
    "                      \"iscrowd\": torch.zeros(len(boxes), dtype=torch.int64)}\n",
    "        else:\n",
    "            transform= A.Compose([\n",
    "                A.HorizontalFlip(p=.5),\n",
    "                A.RandomGamma(p=1),\n",
    "                A.ShiftScaleRotate(rotate_limit=10, p=.5),\n",
    "                A.Cutout(p=.3),\n",
    "                A.RandomBrightness(p=.5),\n",
    "                ToTensorV2()\n",
    "            ])\n",
    "            \n",
    "            sample = transform(image=img)\n",
    "            \n",
    "            target = {\"boxes\": torch.zeros((0,4), dtype=torch.float32),\n",
    "                      \"labels\": torch.zeros(0, dtype=torch.int64),\n",
    "                      \"image_id\": torch.tensor([index]),\n",
    "                      \"area\": torch.zeros(0, dtype=torch.float32),\n",
    "                      \"iscrowd\": torch.zeros((0), dtype=torch.int64)}\n",
    "            \n",
    "        return sample['image']/255, target\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.all_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_box(img, boxes, ax=None): # box format: xyxy\n",
    "    ax = plt.gca() if ax is None else ax\n",
    "    for box in boxes:\n",
    "        rect = patches.Rectangle((box[0], box[1]), box[2]-box[0], box[3]-box[1], linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    \n",
    "train_dataset = LungDataset(train)\n",
    "valid_dataset = LungDataset(valid)\n",
    "\n",
    "image, target = train_dataset[31]\n",
    "\n",
    "image = image.reshape(256, 256)\n",
    "boxes = target['boxes'].tolist()\n",
    "\n",
    "plot_box(image, boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to C:\\Users\\82106/.cache\\torch\\hub\\checkpoints\\fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
      "100%|██████████| 160M/160M [00:51<00:00, 3.22MB/s] \n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "num_classes = 2 # opacity + none\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n",
    "# model.load_state_dict(torch.load('../input/siim-packages/weight/epoch4.pth'))\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.Adam(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras.preprocessing.image as KPImage\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "def read_dicom_image(in_path):\n",
    "    img_arr = pydicom.read_file(in_path).pixel_array\n",
    "    return img_arr/img_arr.max()\n",
    "    \n",
    "class medical_pil():\n",
    "    @staticmethod\n",
    "    def open(in_path):\n",
    "        if '.dcm' in in_path:\n",
    "            c_slice = read_dicom_image(in_path)\n",
    "            int_slice =  (255*c_slice).clip(0, 255).astype(np.uint8) # 8bit images are more friendly\n",
    "            return Image.fromarray(int_slice)\n",
    "        else:\n",
    "            return Image.open(in_path)\n",
    "    fromarray = Image.fromarray\n",
    "KPImage.pil_image = medical_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n train samples 17440\n",
      "n valid samples 2560\n"
     ]
    }
   ],
   "source": [
    "# load and shuffle filenames\n",
    "folder = 'rsna-pneumonia/stage_2_train_images'\n",
    "filenames = os.listdir(folder)\n",
    "random.shuffle(filenames)\n",
    "# split into train and validation filenames\n",
    "n_valid_samples = 2560\n",
    "train_filenames = filenames[n_valid_samples:20000]\n",
    "valid_filenames = filenames[:n_valid_samples]\n",
    "print('n train samples', len(train_filenames))\n",
    "print('n valid samples', len(valid_filenames))\n",
    "n_train_samples = len(filenames) - n_valid_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dictionary\n",
    "pneumonia_locations = {}\n",
    "# load table\n",
    "with open(os.path.join('rsna-pneumonia/stage_2_train_labels.csv'), mode='r') as infile:\n",
    "    # open reader\n",
    "    reader = csv.reader(infile)\n",
    "    # skip header\n",
    "    next(reader, None)\n",
    "    # loop through rows\n",
    "    for rows in reader:\n",
    "        # retrieve information\n",
    "        filename = rows[0]\n",
    "        location = rows[1:5]\n",
    "        pneumonia = rows[5]\n",
    "        # if row contains pneumonia add label to dictionary\n",
    "        # which contains a list of pneumonia locations per filename\n",
    "        if pneumonia == '1':\n",
    "            # convert string to float to int\n",
    "            location = [int(float(i)) for i in location]\n",
    "            # save pneumonia location in dictionary\n",
    "            if filename in pneumonia_locations:\n",
    "                pneumonia_locations[filename].append(location)\n",
    "            else:\n",
    "                pneumonia_locations[filename] = [location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, folder, filenames, pneumonia_locations=None, batch_size=32, image_size=256, shuffle=True, augment=False, predict=False):\n",
    "        self.folder = folder\n",
    "        self.filenames = filenames\n",
    "        self.pneumonia_locations = pneumonia_locations\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.predict = predict\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __load__(self, filename):\n",
    "        # load dicom file as numpy array\n",
    "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
    "        # create empty mask\n",
    "        msk = np.zeros(img.shape)\n",
    "        # get filename without extension\n",
    "        filename = filename.split('.')[0]\n",
    "        # if image contains pneumonia\n",
    "        if filename in pneumonia_locations:\n",
    "            # loop through pneumonia\n",
    "            for location in pneumonia_locations[filename]:\n",
    "                # add 1's at the location of the pneumonia\n",
    "                x, y, w, h = location\n",
    "                msk[y:y+h, x:x+w] = 1\n",
    "        # if augment then horizontal flip half the time\n",
    "        if self.augment and random.random() > 0.5:\n",
    "            img = np.fliplr(img)\n",
    "            msk = np.fliplr(msk)\n",
    "        # resize both image and mask\n",
    "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
    "        msk = resize(msk, (self.image_size, self.image_size), mode='reflect') > 0.45\n",
    "        # add trailing channel dimension\n",
    "        img = np.expand_dims(img, -1)\n",
    "        msk = np.expand_dims(msk, -1)\n",
    "        return img, msk\n",
    "\n",
    "    def __loadpredict__(self, filename):\n",
    "        # load dicom file as numpy array\n",
    "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
    "        # resize image\n",
    "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
    "        # add trailing channel dimension\n",
    "        img = np.expand_dims(img, -1)\n",
    "        return img\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # select batch\n",
    "        filenames = self.filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # predict mode: return images and filenames\n",
    "        if self.predict:\n",
    "            # load files\n",
    "            imgs = [self.__loadpredict__(filename) for filename in filenames]\n",
    "            # create numpy batch\n",
    "            imgs = np.array(imgs)\n",
    "            return imgs, filenames\n",
    "        # train mode: return images and masks\n",
    "        else:\n",
    "            # load files\n",
    "            items = [self.__load__(filename) for filename in filenames]\n",
    "            # unzip images and masks\n",
    "            imgs, msks = zip(*items)\n",
    "            # create numpy batch\n",
    "            imgs = np.array(imgs)\n",
    "            msks = np.array(msks)\n",
    "            return imgs, msks\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.filenames)\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.predict:\n",
    "            # return everything\n",
    "            return int(np.ceil(len(self.filenames) / self.batch_size))\n",
    "        else:\n",
    "            # return full batches only\n",
    "            return int(len(self.filenames) / self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation generators\n",
    "folder = 'rsna-pneumonia/stage_2_train_images'\n",
    "train_gen = generator(folder, train_filenames, pneumonia_locations, batch_size=16, image_size=256, shuffle=True, augment=True, predict=False)\n",
    "valid_gen = generator(folder, valid_filenames, pneumonia_locations, batch_size=16, image_size=256, shuffle=False, predict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'engine'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19484\\2394957348.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'engine'"
     ]
    }
   ],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "num_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, train_gen, device, epoch, print_freq=10)\n",
    "    torch.save(model.state_dict(), f'epoch{epoch}.pth')\n",
    "    evaluate(model, valid_gen, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cf8889d2362d979c1ca60a3272c8483814f41f7f5def47ce260ee0771921932"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
