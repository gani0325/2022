{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/ashishpatel26/lung-opacity-classification-using-densenet-121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/code/kretes/rpn-mask-r-cnn-regions-exploration-on-rsna-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/nazeernazeer/pneumonia-capstone-proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params we will probably want to do some hyperparameter optimization later\n",
    "BASE_MODEL= 'DenseNet121'\n",
    "IMG_SIZE = (512, 512) # [(224, 224), (384, 384), (512, 512), (640, 640)]\n",
    "BATCH_SIZE = 24 # [1, 8, 16, 24]\n",
    "DENSE_COUNT = 128 # [32, 64, 128, 256]\n",
    "DROPOUT = 0.5 # [0, 0.25, 0.5]\n",
    "LEARN_RATE = 1e-4 # [1e-4, 1e-3, 4e-3]\n",
    "TRAIN_SAMPLES = 6000 # [3000, 6000, 15000]\n",
    "TEST_SAMPLES = 600\n",
    "USE_ATTN = False # [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30227 images\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "      <th>class</th>\n",
       "      <th>boxes</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>308eab64-517b-46f1-8865-d9566b087bff</td>\n",
       "      <td>695.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lung Opacity</td>\n",
       "      <td>3</td>\n",
       "      <td>../rsna-pneumonia/stage_2_train_images/308eab6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18694</th>\n",
       "      <td>a75649b5-f044-4b85-86e7-91e6c6051826</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>../rsna-pneumonia/stage_2_train_images/a75649b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3948</th>\n",
       "      <td>342bd0cf-b337-40e9-8512-eb170292e2f2</td>\n",
       "      <td>317.0</td>\n",
       "      <td>519.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Lung Opacity</td>\n",
       "      <td>1</td>\n",
       "      <td>../rsna-pneumonia/stage_2_train_images/342bd0c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId      x      y  width  height  \\\n",
       "3444   308eab64-517b-46f1-8865-d9566b087bff  695.0  558.0  172.0   105.0   \n",
       "18694  a75649b5-f044-4b85-86e7-91e6c6051826    NaN    NaN    NaN     NaN   \n",
       "3948   342bd0cf-b337-40e9-8512-eb170292e2f2  317.0  519.0  121.0   127.0   \n",
       "\n",
       "       Target         class  boxes  \\\n",
       "3444        1  Lung Opacity      3   \n",
       "18694       0        Normal      1   \n",
       "3948        1  Lung Opacity      1   \n",
       "\n",
       "                                                    path  \n",
       "3444   ../rsna-pneumonia/stage_2_train_images/308eab6...  \n",
       "18694  ../rsna-pneumonia/stage_2_train_images/a75649b...  \n",
       "3948   ../rsna-pneumonia/stage_2_train_images/342bd0c...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_bbox_df = pd.read_csv('image_bbox_full.csv')\n",
    "image_bbox_df['path'] = image_bbox_df['path'].map(lambda x: \n",
    "                                                  x.replace('input', \n",
    "                                                            'rsna-pneumonia'))\n",
    "print(image_bbox_df.shape[0], 'images')\n",
    "image_bbox_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "      <th>class</th>\n",
       "      <th>boxes</th>\n",
       "      <th>path</th>\n",
       "      <th>class_idx</th>\n",
       "      <th>class_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27726</th>\n",
       "      <td>ec3697bd-184e-44ba-9688-ff8d5fbf9bbc</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>../rsna-pneumonia/stage_2_train_images/ec3697b...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18645</th>\n",
       "      <td>a6fc3abd-e573-4412-991d-65f6bf3e5b17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>No Lung Opacity / Not Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>../rsna-pneumonia/stage_2_train_images/a6fc3ab...</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14218</th>\n",
       "      <td>83e0c51c-af5b-457e-849b-bfdf083782ed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>../rsna-pneumonia/stage_2_train_images/83e0c51...</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  patientId   x   y  width  height  Target  \\\n",
       "27726  ec3697bd-184e-44ba-9688-ff8d5fbf9bbc NaN NaN    NaN     NaN       0   \n",
       "18645  a6fc3abd-e573-4412-991d-65f6bf3e5b17 NaN NaN    NaN     NaN       0   \n",
       "14218  83e0c51c-af5b-457e-849b-bfdf083782ed NaN NaN    NaN     NaN       0   \n",
       "\n",
       "                              class  boxes  \\\n",
       "27726                        Normal      1   \n",
       "18645  No Lung Opacity / Not Normal      1   \n",
       "14218                        Normal      1   \n",
       "\n",
       "                                                    path  class_idx  \\\n",
       "27726  ../rsna-pneumonia/stage_2_train_images/ec3697b...          2   \n",
       "18645  ../rsna-pneumonia/stage_2_train_images/a6fc3ab...          1   \n",
       "14218  ../rsna-pneumonia/stage_2_train_images/83e0c51...          2   \n",
       "\n",
       "             class_vec  \n",
       "27726  [0.0, 0.0, 1.0]  \n",
       "18645  [0.0, 1.0, 0.0]  \n",
       "14218  [0.0, 0.0, 1.0]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the labels in the right format\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "class_enc = LabelEncoder()\n",
    "image_bbox_df['class_idx'] = class_enc.fit_transform(image_bbox_df['class'])\n",
    "oh_enc = OneHotEncoder(sparse=False)\n",
    "image_bbox_df['class_vec'] = oh_enc.fit_transform(\n",
    "    image_bbox_df['class_idx'].values.reshape(-1, 1)).tolist() \n",
    "image_bbox_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 11) training data\n",
      "(5000, 11) validation data\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "image_df = image_bbox_df.groupby('patientId').apply(lambda x: x.sample(1))\n",
    "image_df = image_df[:20000]\n",
    "raw_train_df, valid_df = train_test_split(image_df, test_size=0.25, random_state=200,\n",
    "                                    stratify=image_df['class'])\n",
    "print(raw_train_df.shape, 'training data')\n",
    "print(valid_df.shape, 'validation data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 new training size\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20, 10))\n",
    "raw_train_df.groupby('class').size().plot.bar(ax=ax1)\n",
    "train_df = raw_train_df.groupby('class').\\\n",
    "    apply(lambda x: x.sample(TRAIN_SAMPLES//3)).\\\n",
    "    reset_index(drop=True)\n",
    "train_df.groupby('class').size().plot.bar(ax=ax2) \n",
    "print(train_df.shape[0], 'new training size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\dask\\dataframe\\utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "import keras.preprocessing.image as KPImage\n",
    "from PIL import Image\n",
    "import pydicom\n",
    "def read_dicom_image(in_path):\n",
    "    img_arr = pydicom.read_file(in_path).pixel_array\n",
    "    return img_arr/img_arr.max()\n",
    "    \n",
    "class medical_pil():\n",
    "    @staticmethod\n",
    "    def open(in_path):\n",
    "        if '.dcm' in in_path:\n",
    "            c_slice = read_dicom_image(in_path)\n",
    "            int_slice =  (255*c_slice).clip(0, 255).astype(np.uint8) # 8bit images are more friendly\n",
    "            return Image.fromarray(int_slice)\n",
    "        else:\n",
    "            return Image.open(in_path)\n",
    "    fromarray = Image.fromarray\n",
    "KPImage.pil_image = medical_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # keras 2.2\n",
    "    from keras_preprocessing.image import ImageDataGenerator\n",
    "except:\n",
    "    from keras.preprocessing.image import ImageDataGenerator\n",
    "if BASE_MODEL=='VGG16':\n",
    "    from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='RESNET52':\n",
    "    from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='InceptionV3':\n",
    "    from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='Xception':\n",
    "    from keras.applications.xception import Xception as PTModel, preprocess_input\n",
    "elif BASE_MODEL=='DenseNet169': \n",
    "    keras.applications.densenet.DenseNet169\n",
    "elif BASE_MODEL=='DenseNet121':\n",
    "    keras.applications.densenet.DenseNet121\n",
    "# elif BASE_MODEL=='DenseNet169': \n",
    "#     keras.applications.densenet.DenseNet169 as PTModel, preprocess_input\n",
    "# elif BASE_MODEL=='DenseNet121':\n",
    "#     keras.applications.densenet.DenseNet121 as PTModel, preprocess_input\n",
    "else:\n",
    "    raise ValueError('Unknown model: {}'.format(BASE_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen_args = dict(samplewise_center=False, \n",
    "                              samplewise_std_normalization=False, \n",
    "                              horizontal_flip = True, \n",
    "                              vertical_flip = False, \n",
    "                              height_shift_range = 0.05, \n",
    "                              width_shift_range = 0.02, \n",
    "                              rotation_range = 3, \n",
    "                              shear_range = 0.01,\n",
    "                              fill_mode = 'nearest',\n",
    "                              zoom_range = 0.05,\n",
    "                               preprocessing_function=preprocess_input)\n",
    "img_gen = ImageDataGenerator(**img_gen_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, seed = None, **dflow_args):\n",
    "    base_dir = os.path.dirname(in_df[path_col].values[0])\n",
    "    print('## Ignore next message from keras, values are replaced anyways: seed: {}'.format(seed))\n",
    "    df_gen = img_data_gen.flow_from_directory(base_dir, \n",
    "                                     class_mode = 'sparse',\n",
    "                                              seed = seed,\n",
    "                                    **dflow_args)\n",
    "    df_gen.filenames = in_df[path_col].values\n",
    "    df_gen.classes = np.stack(in_df[y_col].values,0)\n",
    "    df_gen.samples = in_df.shape[0]\n",
    "    df_gen.n = in_df.shape[0]\n",
    "    df_gen._set_index_array()\n",
    "    df_gen.directory = '' # since we have the full path\n",
    "    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n",
    "    return df_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ../rsna-pneumonia/stage_2_train_images/0004cfa...\n",
       "1        ../rsna-pneumonia/stage_2_train_images/000924c...\n",
       "2        ../rsna-pneumonia/stage_2_train_images/000db69...\n",
       "3        ../rsna-pneumonia/stage_2_train_images/000db69...\n",
       "4        ../rsna-pneumonia/stage_2_train_images/000fe35...\n",
       "                               ...                        \n",
       "30222    ../rsna-pneumonia/stage_2_train_images/fffb239...\n",
       "30223    ../rsna-pneumonia/stage_2_train_images/fffba05...\n",
       "30224    ../rsna-pneumonia/stage_2_train_images/fffc95b...\n",
       "30225    ../rsna-pneumonia/stage_2_train_images/fffcff1...\n",
       "30226    ../rsna-pneumonia/stage_2_train_images/fffec09...\n",
       "Name: path, Length: 30227, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_bbox_df['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       ../rsna-pneumonia/stage_2_train_images/09b2d54...\n",
       "1       ../rsna-pneumonia/stage_2_train_images/c1ffc79...\n",
       "2       ../rsna-pneumonia/stage_2_train_images/3a146de...\n",
       "3       ../rsna-pneumonia/stage_2_train_images/8f0e79e...\n",
       "4       ../rsna-pneumonia/stage_2_train_images/b1a8c34...\n",
       "                              ...                        \n",
       "5995    ../rsna-pneumonia/stage_2_train_images/58119b6...\n",
       "5996    ../rsna-pneumonia/stage_2_train_images/7fe0839...\n",
       "5997    ../rsna-pneumonia/stage_2_train_images/574f1f6...\n",
       "5998    ../rsna-pneumonia/stage_2_train_images/901950a...\n",
       "5999    ../rsna-pneumonia/stage_2_train_images/7f1e4c1...\n",
       "Name: path, Length: 6000, dtype: object"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [1.0, 0.0, 0.0]\n",
       "1       [1.0, 0.0, 0.0]\n",
       "2       [1.0, 0.0, 0.0]\n",
       "3       [1.0, 0.0, 0.0]\n",
       "4       [1.0, 0.0, 0.0]\n",
       "             ...       \n",
       "5995    [0.0, 0.0, 1.0]\n",
       "5996    [0.0, 0.0, 1.0]\n",
       "5997    [0.0, 0.0, 1.0]\n",
       "5998    [0.0, 0.0, 1.0]\n",
       "5999    [0.0, 0.0, 1.0]\n",
       "Name: class_vec, Length: 6000, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['class_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'path_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3081\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3082\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'path_col'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4432\\933297644.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m                             \u001b[0mtarget_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                              \u001b[0mcolor_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rgb'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                             batch_size = BATCH_SIZE)\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4432\\3744155485.py\u001b[0m in \u001b[0;36mflow_from_dataframe\u001b[1;34m(img_data_gen, in_df, path_col, y_col, seed, **dflow_args)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mflow_from_dataframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data_gen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_df\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mdflow_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mbase_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'path_col'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'## Ignore next message from keras, values are replaced anyways: seed: {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     df_gen = img_data_gen.flow_from_directory(base_dir, \n\u001b[0;32m      5\u001b[0m                                      \u001b[0mclass_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'sparse'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3081\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3083\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'path_col'"
     ]
    }
   ],
   "source": [
    "train_gen = flow_from_dataframe(img_gen, train_df, \n",
    "                             path_col = 'path',\n",
    "                            y_col = 'class_vec', \n",
    "                            target_size = IMG_SIZE,\n",
    "                             color_mode = 'rgb',\n",
    "                            batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n train samples 17440\n",
      "n valid samples 2560\n"
     ]
    }
   ],
   "source": [
    "# load and shuffle filenames\n",
    "folder = 'rsna-pneumonia/stage_2_train_images'\n",
    "filenames = os.listdir(folder)\n",
    "random.shuffle(filenames)\n",
    "# split into train and validation filenames\n",
    "n_valid_samples = 2560\n",
    "train_filenames = filenames[n_valid_samples:20000]\n",
    "valid_filenames = filenames[:n_valid_samples]\n",
    "print('n train samples', len(train_filenames))\n",
    "print('n valid samples', len(valid_filenames))\n",
    "n_train_samples = len(filenames) - n_valid_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dictionary\n",
    "pneumonia_locations = {}\n",
    "# load table\n",
    "with open(os.path.join('rsna-pneumonia/stage_2_train_labels.csv'), mode='r') as infile:\n",
    "    # open reader\n",
    "    reader = csv.reader(infile)\n",
    "    # skip header\n",
    "    next(reader, None)\n",
    "    # loop through rows\n",
    "    for rows in reader:\n",
    "        # retrieve information\n",
    "        filename = rows[0]\n",
    "        location = rows[1:5]\n",
    "        pneumonia = rows[5]\n",
    "        # if row contains pneumonia add label to dictionary\n",
    "        # which contains a list of pneumonia locations per filename\n",
    "        if pneumonia == '1':\n",
    "            # convert string to float to int\n",
    "            location = [int(float(i)) for i in location]\n",
    "            # save pneumonia location in dictionary\n",
    "            if filename in pneumonia_locations:\n",
    "                pneumonia_locations[filename].append(location)\n",
    "            else:\n",
    "                pneumonia_locations[filename] = [location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, folder, filenames, pneumonia_locations=None, batch_size=32, image_size=256, shuffle=True, augment=False, predict=False):\n",
    "        self.folder = folder\n",
    "        self.filenames = filenames\n",
    "        self.pneumonia_locations = pneumonia_locations\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.predict = predict\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __load__(self, filename):\n",
    "        # load dicom file as numpy array\n",
    "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
    "        # create empty mask\n",
    "        msk = np.zeros(img.shape)\n",
    "        # get filename without extension\n",
    "        filename = filename.split('.')[0]\n",
    "        # if image contains pneumonia\n",
    "        if filename in pneumonia_locations:\n",
    "            # loop through pneumonia\n",
    "            for location in pneumonia_locations[filename]:\n",
    "                # add 1's at the location of the pneumonia\n",
    "                x, y, w, h = location\n",
    "                msk[y:y+h, x:x+w] = 1\n",
    "        # if augment then horizontal flip half the time\n",
    "        if self.augment and random.random() > 0.5:\n",
    "            img = np.fliplr(img)\n",
    "            msk = np.fliplr(msk)\n",
    "        # resize both image and mask\n",
    "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
    "        msk = resize(msk, (self.image_size, self.image_size), mode='reflect') > 0.45\n",
    "        # add trailing channel dimension\n",
    "        img = np.expand_dims(img, -1)\n",
    "        msk = np.expand_dims(msk, -1)\n",
    "        return img, msk\n",
    "\n",
    "    def __loadpredict__(self, filename):\n",
    "        # load dicom file as numpy array\n",
    "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
    "        # resize image\n",
    "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
    "        # add trailing channel dimension\n",
    "        img = np.expand_dims(img, -1)\n",
    "        return img\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # select batch\n",
    "        filenames = self.filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # predict mode: return images and filenames\n",
    "        if self.predict:\n",
    "            # load files\n",
    "            imgs = [self.__loadpredict__(filename) for filename in filenames]\n",
    "            # create numpy batch\n",
    "            imgs = np.array(imgs)\n",
    "            return imgs, filenames\n",
    "        # train mode: return images and masks\n",
    "        else:\n",
    "            # load files\n",
    "            items = [self.__load__(filename) for filename in filenames]\n",
    "            # unzip images and masks\n",
    "            imgs, msks = zip(*items)\n",
    "            # create numpy batch\n",
    "            imgs = np.array(imgs)\n",
    "            msks = np.array(msks)\n",
    "            return imgs, msks\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.filenames)\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.predict:\n",
    "            # return everything\n",
    "            return int(np.ceil(len(self.filenames) / self.batch_size))\n",
    "        else:\n",
    "            # return full batches only\n",
    "            return int(len(self.filenames) / self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation generators\n",
    "folder = 'rsna-pneumonia/stage_2_train_images'\n",
    "train_gen = generator(folder, train_filenames, pneumonia_locations, batch_size=16, image_size=256, shuffle=True, augment=True, predict=False)\n",
    "valid_gen = generator(folder, valid_filenames, pneumonia_locations, batch_size=16, image_size=256, shuffle=False, predict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1090\n"
     ]
    }
   ],
   "source": [
    "print(len(train_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(800, 11)\n"
     ]
    }
   ],
   "source": [
    "# t_x, t_y = train_test_split(train_gen, test_size=0.25, random_state=124)\n",
    "t_x = train_gen[:800]\n",
    "t_y = train_gen[800:]\n",
    "print(t_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PTModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4432\\313302336.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m base_pretrained_model = PTModel(input_shape =  t_x.shape[1:], \n\u001b[0m\u001b[0;32m      2\u001b[0m                               include_top = False, weights = 'imagenet')\n\u001b[0;32m      3\u001b[0m \u001b[0mbase_pretrained_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'PTModel' is not defined"
     ]
    }
   ],
   "source": [
    "base_pretrained_model = PTModel(input_shape =  t_x.shape[1:], \n",
    "                              include_top = False, weights = 'imagenet')\n",
    "base_pretrained_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'base_pretrained_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4432\\3660176769.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpt_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_pretrained_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output_shape_at\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'feature_input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpt_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_pretrained_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_output_shape_at\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'base_pretrained_model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten, Input, Conv2D, multiply, LocallyConnected2D, Lambda, AvgPool2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "pt_features = Input(base_pretrained_model.get_output_shape_at(0)[1:], name = 'feature_input')\n",
    "pt_depth = base_pretrained_model.get_output_shape_at(0)[-1]\n",
    "from keras.layers import BatchNormalization\n",
    "bn_features = BatchNormalization()(pt_features)\n",
    "gap = GlobalAveragePooling2D()(bn_features)\n",
    "\n",
    "gap_dr = Dropout(DROPOUT)(gap)\n",
    "dr_steps = Dropout(DROPOUT)(Dense(DENSE_COUNT, activation = 'elu')(gap_dr))\n",
    "out_layer = Dense(t_y.shape[1], activation = 'softmax')(dr_steps)\n",
    "\n",
    "attn_model = Model(inputs = [pt_features], \n",
    "                   outputs = [out_layer], name = 'trained_model')\n",
    "\n",
    "attn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cf8889d2362d979c1ca60a3272c8483814f41f7f5def47ce260ee0771921932"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
