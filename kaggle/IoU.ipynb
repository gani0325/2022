{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('rsna-pneumonia/stage_2_train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>264.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>562.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>256.0</td>\n",
       "      <td>453.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>00569f44-917d-4c86-a842-81832af98c30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>006cec2e-6ce2-4549-bffa-eadfcd1e9970</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00704310-78a8-4b38-8475-49f4573b2dbb</td>\n",
       "      <td>323.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00704310-78a8-4b38-8475-49f4573b2dbb</td>\n",
       "      <td>695.0</td>\n",
       "      <td>575.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>008c19e8-a820-403a-930a-bc74a4053664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>009482dc-3db5-48d4-8580-5c89c4f01334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>009eb222-eabc-4150-8121-d5a6d06b8ebf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00a85be6-6eb0-421d-8acf-ff2dc0007e8a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00aecb01-a116-45a2-956c-08d2fa55433f</td>\n",
       "      <td>288.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00aecb01-a116-45a2-956c-08d2fa55433f</td>\n",
       "      <td>547.0</td>\n",
       "      <td>299.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00c0b293-48e7-4e16-ac76-9269ba535a62</td>\n",
       "      <td>306.0</td>\n",
       "      <td>544.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00c0b293-48e7-4e16-ac76-9269ba535a62</td>\n",
       "      <td>650.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00d7c36e-3cdf-4df6-ac03-6c30cdc8e85b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00f08de1-517e-4652-a04f-d1dc9ee48593</td>\n",
       "      <td>181.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>206.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               patientId      x      y  width  height  Target\n",
       "0   0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN       0\n",
       "1   00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN       0\n",
       "2   00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN       0\n",
       "3   003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN       0\n",
       "4   00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1\n",
       "5   00436515-870c-4b36-a041-de91049b9ab4  562.0  152.0  256.0   453.0       1\n",
       "6   00569f44-917d-4c86-a842-81832af98c30    NaN    NaN    NaN     NaN       0\n",
       "7   006cec2e-6ce2-4549-bffa-eadfcd1e9970    NaN    NaN    NaN     NaN       0\n",
       "8   00704310-78a8-4b38-8475-49f4573b2dbb  323.0  577.0  160.0   104.0       1\n",
       "9   00704310-78a8-4b38-8475-49f4573b2dbb  695.0  575.0  162.0   137.0       1\n",
       "10  008c19e8-a820-403a-930a-bc74a4053664    NaN    NaN    NaN     NaN       0\n",
       "11  009482dc-3db5-48d4-8580-5c89c4f01334    NaN    NaN    NaN     NaN       0\n",
       "12  009eb222-eabc-4150-8121-d5a6d06b8ebf    NaN    NaN    NaN     NaN       0\n",
       "13  00a85be6-6eb0-421d-8acf-ff2dc0007e8a    NaN    NaN    NaN     NaN       0\n",
       "14  00aecb01-a116-45a2-956c-08d2fa55433f  288.0  322.0   94.0   135.0       1\n",
       "15  00aecb01-a116-45a2-956c-08d2fa55433f  547.0  299.0  119.0   165.0       1\n",
       "16  00c0b293-48e7-4e16-ac76-9269ba535a62  306.0  544.0  168.0   244.0       1\n",
       "17  00c0b293-48e7-4e16-ac76-9269ba535a62  650.0  511.0  206.0   284.0       1\n",
       "18  00d7c36e-3cdf-4df6-ac03-6c30cdc8e85b    NaN    NaN    NaN     NaN       0\n",
       "19  00f08de1-517e-4652-a04f-d1dc9ee48593  181.0  184.0  206.0   506.0       1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bbox_target'] = (df['x'].astype(str) +\n",
    "                    ' ' + \n",
    "                    df['y'].astype(str) +\n",
    "                    ' ' +\n",
    "                    df['width'].astype(str) +\n",
    "                    ' ' +\n",
    "                    df['height'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[:, 'bbox_target'] = df.loc[:, 'bbox_target'].map(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>Target</th>\n",
       "      <th>bbox_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00313ee0-9eaa-42f4-b0ab-c148ed3241cd</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00322d4d-1c29-4943-afc9-b6754be640eb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003d8fa0-6bf1-40ed-b54c-ac657f8495c5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00436515-870c-4b36-a041-de91049b9ab4</td>\n",
       "      <td>264.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>379.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[264.0, 152.0, 213.0, 379.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              patientId      x      y  width  height  Target  \\\n",
       "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6    NaN    NaN    NaN     NaN       0   \n",
       "1  00313ee0-9eaa-42f4-b0ab-c148ed3241cd    NaN    NaN    NaN     NaN       0   \n",
       "2  00322d4d-1c29-4943-afc9-b6754be640eb    NaN    NaN    NaN     NaN       0   \n",
       "3  003d8fa0-6bf1-40ed-b54c-ac657f8495c5    NaN    NaN    NaN     NaN       0   \n",
       "4  00436515-870c-4b36-a041-de91049b9ab4  264.0  152.0  213.0   379.0       1   \n",
       "\n",
       "                    bbox_target  \n",
       "0          [nan, nan, nan, nan]  \n",
       "1          [nan, nan, nan, nan]  \n",
       "2          [nan, nan, nan, nan]  \n",
       "3          [nan, nan, nan, nan]  \n",
       "4  [264.0, 152.0, 213.0, 379.0]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby(['patientId'], as_index = False)['bbox_target'].agg('sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patientId</th>\n",
       "      <th>bbox_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0004cfab-14fd-4e49-80ba-63a80b6bddd6</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000924cf-0f8d-42bd-9158-1af53881a557</td>\n",
       "      <td>[nan, nan, nan, nan]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000db696-cf54-4385-b10b-6b16fbb3f985</td>\n",
       "      <td>[316.0, 318.0, 170.0, 478.0, 660.0, 375.0, 146...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000fe35a-2649-43d4-b027-e67796d412e0</td>\n",
       "      <td>[570.0, 282.0, 269.0, 409.0, 83.0, 227.0, 296....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001031d9-f904-4a23-b3e5-2c088acd19c6</td>\n",
       "      <td>[66.0, 160.0, 373.0, 608.0, 552.0, 164.0, 376....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              patientId  \\\n",
       "0  0004cfab-14fd-4e49-80ba-63a80b6bddd6   \n",
       "1  000924cf-0f8d-42bd-9158-1af53881a557   \n",
       "2  000db696-cf54-4385-b10b-6b16fbb3f985   \n",
       "3  000fe35a-2649-43d4-b027-e67796d412e0   \n",
       "4  001031d9-f904-4a23-b3e5-2c088acd19c6   \n",
       "\n",
       "                                         bbox_target  \n",
       "0                               [nan, nan, nan, nan]  \n",
       "1                               [nan, nan, nan, nan]  \n",
       "2  [316.0, 318.0, 170.0, 478.0, 660.0, 375.0, 146...  \n",
       "3  [570.0, 282.0, 269.0, 409.0, 83.0, 227.0, 296....  \n",
       "4  [66.0, 160.0, 373.0, 608.0, 552.0, 164.0, 376....  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(oof_preds0, on = 'patientId', how = 'left')\n",
    "df = df.merge(oof_preds1, on = 'patientId', how = 'left')\n",
    "df = df.merge(oof_preds2, on = 'patientId', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/cchadha/cnn-segmentation-cv-with-oof-preds-on-train-set/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import pydicom\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import measure\n",
    "from skimage.transform import resize\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty dictionary\n",
    "pneumonia_locations = {}\n",
    "# load table\n",
    "with open(os.path.join('rsna-pneumonia/stage_2_train_labels.csv'), mode='r') as infile:\n",
    "    # open reader\n",
    "    reader = csv.reader(infile)\n",
    "    # skip header\n",
    "    next(reader, None)\n",
    "    # loop through rows\n",
    "    for rows in reader:\n",
    "        # retrieve information\n",
    "        filename = rows[0]\n",
    "        location = rows[1:5]\n",
    "        pneumonia = rows[5]\n",
    "        # if row contains pneumonia add label to dictionary\n",
    "        # which contains a list of pneumonia locations per filename\n",
    "        if pneumonia == '1':\n",
    "            # convert string to float to int\n",
    "            location = [int(float(i)) for i in location]\n",
    "            # save pneumonia location in dictionary\n",
    "            if filename in pneumonia_locations:\n",
    "                pneumonia_locations[filename].append(location)\n",
    "            else:\n",
    "                pneumonia_locations[filename] = [location]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate: 0.00042\n",
      "beta (momentum): 0.94\n",
      "batch size: 16\n"
     ]
    }
   ],
   "source": [
    "# load and shuffle filenames\n",
    "folder = 'rsna-pneumonia/stage_2_train_images'\n",
    "filenames = os.listdir(folder)\n",
    "SEED = 1001\n",
    "BATCH_SIZE = 16\n",
    "IMAGE_SIZE = 320\n",
    "lr = 0.00042\n",
    "beta = 0.94\n",
    "# lr = 10**(-4*np.random.rand())\n",
    "# beta = np.random.uniform(0.9,0.99)\n",
    "# BATCH_SIZE = random.choice([14,15,16,17,18])\n",
    "nn_depth = 4\n",
    "n_epochs = 1\n",
    "n_splits = 3\n",
    "stratified = True\n",
    "debug = False\n",
    "\n",
    "print('learning rate: {}'.format(lr))\n",
    "print('beta (momentum): {}'.format(beta))\n",
    "print('batch size: {}'.format(BATCH_SIZE))\n",
    "\n",
    "labels = pd.read_csv('rsna-pneumonia/stage_2_train_labels.csv')\n",
    "labels = labels.drop(['x', 'y', 'width', 'height'], axis=1)\n",
    "labels = labels.groupby('patientId', as_index=False).agg('mean')\n",
    "labels.loc[:,'patientId'] = labels.loc[:,'patientId'] + '.dcm'\n",
    "\n",
    "if debug == True:\n",
    "    X = labels['patientId'][:1000].values\n",
    "    y = labels['Target'][:1000].values\n",
    "else:\n",
    "    X = labels['patientId'].values\n",
    "    y = labels['Target'].values\n",
    "del labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class generator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, folder, filenames, pneumonia_locations=None, batch_size=32, image_size=320, shuffle=True, augment=False, predict=False):\n",
    "        self.folder = folder\n",
    "        self.filenames = filenames\n",
    "        self.pneumonia_locations = pneumonia_locations\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augment = augment\n",
    "        self.predict = predict\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __load__(self, filename):\n",
    "        # load dicom file as numpy array\n",
    "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
    "        # create empty mask\n",
    "        msk = np.zeros(img.shape)\n",
    "        # get filename without extension\n",
    "        filename = filename.split('.')[0]\n",
    "        # if image contains pneumonia\n",
    "        if filename in pneumonia_locations:\n",
    "            # loop through pneumonia\n",
    "            for location in pneumonia_locations[filename]:\n",
    "                # add 1's at the location of the pneumonia\n",
    "                x, y, w, h = location\n",
    "                msk[y:y+h, x:x+w] = 1\n",
    "        # if augment then horizontal flip half the time\n",
    "        if self.augment and random.random() > 0.5:\n",
    "            img = np.fliplr(img)\n",
    "            msk = np.fliplr(msk)\n",
    "        # resize both image and mask\n",
    "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
    "        msk = resize(msk, (self.image_size, self.image_size), mode='reflect') > 0.5\n",
    "        # add trailing channel dimension\n",
    "        img = np.expand_dims(img, -1)\n",
    "        msk = np.expand_dims(msk, -1)\n",
    "        return img, msk\n",
    "    \n",
    "    def __loadpredict__(self, filename):\n",
    "        # load dicom file as numpy array\n",
    "        img = pydicom.dcmread(os.path.join(self.folder, filename)).pixel_array\n",
    "        # resize image\n",
    "        img = resize(img, (self.image_size, self.image_size), mode='reflect')\n",
    "        # add trailing channel dimension\n",
    "        img = np.expand_dims(img, -1)\n",
    "        return img\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # select batch\n",
    "        filenames = self.filenames[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # predict mode: return images and filenames\n",
    "        if self.predict:\n",
    "            # load files\n",
    "            imgs = [self.__loadpredict__(filename) for filename in filenames]\n",
    "            # create numpy batch\n",
    "            imgs = np.array(imgs)\n",
    "            return imgs, filenames\n",
    "        # train mode: return images and masks\n",
    "        else:\n",
    "            # load files\n",
    "            items = [self.__load__(filename) for filename in filenames]\n",
    "            # unzip images and masks\n",
    "            imgs, msks = zip(*items)\n",
    "            # create numpy batch\n",
    "            imgs = np.array(imgs)\n",
    "            msks = np.array(msks)\n",
    "            return imgs, msks\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.filenames)\n",
    "        \n",
    "    def __len__(self):\n",
    "        if self.predict:\n",
    "            # return everything\n",
    "            return int(np.ceil(len(self.filenames) / self.batch_size))\n",
    "        else:\n",
    "            # return full batches only\n",
    "            return int(len(self.filenames) / self.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_downsample(channels, inputs):\n",
    "    x = keras.layers.BatchNormalization(momentum=beta)(inputs)\n",
    "    x = keras.layers.LeakyReLU(0)(x)\n",
    "    x = keras.layers.Conv2D(channels, 1, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.MaxPool2D(2)(x)\n",
    "    return x\n",
    "\n",
    "def create_resblock(channels, inputs):\n",
    "    x = keras.layers.BatchNormalization(momentum=beta)(inputs)\n",
    "    x = keras.layers.LeakyReLU(0)(x)\n",
    "#     x = keras.layers.Dropout(0.3)(x)\n",
    "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
    "    x = keras.layers.BatchNormalization(momentum=beta)(x)\n",
    "    x = keras.layers.LeakyReLU(0)(x)\n",
    "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(x)\n",
    "    return keras.layers.add([x, inputs])\n",
    "\n",
    "def create_network(input_size, channels, n_blocks=2, depth=4):\n",
    "    # input\n",
    "    inputs = keras.Input(shape=(input_size, input_size, 1))\n",
    "    x = keras.layers.Conv2D(channels, 3, padding='same', use_bias=False)(inputs)\n",
    "    # residual blocks\n",
    "    for d in range(depth):\n",
    "        channels = channels * 2\n",
    "        x = create_downsample(channels, x)\n",
    "        for b in range(n_blocks):\n",
    "            x = create_resblock(channels, x)\n",
    "    # output\n",
    "    x = keras.layers.BatchNormalization(momentum=beta)(x)\n",
    "    x = keras.layers.LeakyReLU(0)(x)\n",
    "    x = keras.layers.Conv2D(256, 1, activation=None)(x)\n",
    "    x = keras.layers.BatchNormalization(momentum=beta)(x)\n",
    "    x = keras.layers.LeakyReLU(0)(x)\n",
    "    x = keras.layers.Conv2DTranspose(128, (8,8), (4,4), padding=\"same\", activation=None)(x)\n",
    "    x = keras.layers.BatchNormalization(momentum=beta)(x)\n",
    "    x = keras.layers.LeakyReLU(0)(x)\n",
    "    x = keras.layers.Conv2D(1, 1, activation='sigmoid')(x)\n",
    "    outputs = keras.layers.UpSampling2D(2**(depth-2))(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# define iou or jaccard loss function\n",
    "def iou_loss(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    score = (intersection + 1.) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection + 1.)\n",
    "    return 1 - score\n",
    "\n",
    "# combine bce loss and iou loss\n",
    "def iou_bce_loss(y_true, y_pred):\n",
    "    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) + 0.5 * iou_loss(y_true, y_pred)\n",
    "    \n",
    "# mean iou as a metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    intersect = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    smooth = tf.ones(tf.shape(intersect))\n",
    "    return tf.reduce_mean((intersect + smooth) / (union - intersect + smooth))\n",
    "\n",
    "# create network and compiler\n",
    "model = create_network(input_size=IMAGE_SIZE, channels=32, n_blocks=2, depth=4)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=iou_bce_loss,\n",
    "              metrics=['accuracy', mean_iou])\n",
    "\n",
    "\n",
    "# create network and compiler\n",
    "model = create_network(input_size=IMAGE_SIZE, channels=32, n_blocks=2, depth=nn_depth)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=iou_bce_loss,\n",
    "              metrics=['accuracy', mean_iou])\n",
    "\n",
    "# cosine learning rate annealing\n",
    "def cosine_annealing(x):\n",
    "    epochs = 20\n",
    "    return lr*(np.cos(np.pi*x/epochs)+1.)/2\n",
    "learning_rate = tf.keras.callbacks.LearningRateScheduler(cosine_annealing)\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n test samples: 3000\n"
     ]
    }
   ],
   "source": [
    "# load and shuffle filenames\n",
    "folder = 'rsna-pneumonia/stage_2_test_images'\n",
    "test_filenames = os.listdir(folder)\n",
    "#test_filenames = test_filenames[:1000]\n",
    "print('n test samples:', len(test_filenames))\n",
    "\n",
    "\n",
    "# create test generator with predict flag set to True\n",
    "test_gen = generator(folder, test_filenames, None, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=False, predict=True)\n",
    "\n",
    "def test_pred(test_gen, test_filenames):\n",
    "\n",
    "    # create submission dictionary\n",
    "    submission_dict = {}\n",
    "    # loop through testset\n",
    "    for imgs, filenames in test_gen:\n",
    "        # predict batch of images\n",
    "        preds = model.predict(imgs)\n",
    "\n",
    "        # loop through batch\n",
    "        for pred, filename in zip(preds, filenames):\n",
    "            \n",
    "            # resize predicted mask\n",
    "            pred = resize(pred, (1024, 1024), mode='reflect')\n",
    "            # threshold predicted mask\n",
    "            comp = pred[:, :, 0] > 0.5\n",
    "            # apply connected components\n",
    "            comp = measure.label(comp)\n",
    "            # apply bounding boxes\n",
    "            predictionString = ''\n",
    "            for region in measure.regionprops(comp):\n",
    "                # retrieve x, y, height and width\n",
    "                y, x, y2, x2 = region.bbox\n",
    "                height = y2 - y\n",
    "                width = x2 - x\n",
    "                # proxy for confidence score\n",
    "                conf = np.mean(pred[y:y+height, x:x+width])\n",
    "                # add to predictionString\n",
    "                predictionString += str(conf) + ' ' + str(x) + ' ' + str(y) + ' ' + str(width) + ' ' + str(height) + ' '\n",
    "            \n",
    "            # add filename and predictionString to dictionary\n",
    "            filename = filename.split('.')[0]\n",
    "            submission_dict[filename] = predictionString\n",
    "        # stop if we've got them all\n",
    "        if len(submission_dict) >= len(test_filenames):\n",
    "            break\n",
    "\n",
    "    print(\"Done predicting...\")\n",
    "    \n",
    "    return submission_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.generator object at 0x000002793EA92AC8>\n",
      "<__main__.generator object at 0x000002793A087B48>\n",
      "WARNING:tensorflow:From c:\\Users\\82106\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      " 670/1111 [=================>............] - ETA: 5:04:05 - loss: 7.9502 - acc: 0.9591 - mean_iou: 0.5340"
     ]
    }
   ],
   "source": [
    "# create train and validation generators\n",
    "folder = 'rsna-pneumonia/stage_2_train_images'\n",
    "\n",
    "if stratified == True:\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=SEED, shuffle=True)\n",
    "    for n_fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        train_gen = generator(folder, X[train_idx], pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=True, predict=False)\n",
    "        valid_gen = generator(folder, X[val_idx], pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=False, predict=False)\n",
    "        print(train_gen)\n",
    "        print(valid_gen)\n",
    "        history = model.fit_generator(train_gen, validation_data=valid_gen, callbacks=[learning_rate], epochs=n_epochs, shuffle=True)\n",
    "        \n",
    "        valid_gen = generator(folder, X[val_idx], pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=False, predict=True)\n",
    "        oof_dict = test_pred(valid_gen, X[val_idx])\n",
    "        \n",
    "        # save dictionary as csv file\n",
    "        oof = pd.DataFrame.from_dict(oof_dict,orient='index')\n",
    "        oof.index.names = ['patientId']\n",
    "        oof.columns = ['PredictionString']\n",
    "        oof.to_csv('oof_preds' + str(n_fold) + '.csv')\n",
    "        \n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(131)\n",
    "        plt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "        plt.plot(history.epoch, history.history[\"val_loss\"], label=\"Valid loss\")\n",
    "        plt.legend()\n",
    "        plt.subplot(132)\n",
    "        plt.plot(history.epoch, history.history[\"acc\"], label=\"Train accuracy\")\n",
    "        plt.plot(history.epoch, history.history[\"val_acc\"], label=\"Valid accuracy\")\n",
    "        plt.legend()\n",
    "        plt.subplot(133)\n",
    "        plt.plot(history.epoch, history.history[\"mean_iou\"], label=\"Train iou\")\n",
    "        plt.plot(history.epoch, history.history[\"val_mean_iou\"], label=\"Valid iou\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print('Final epoch train loss = {:.3f}'.format(history.history['loss'][-1]))\n",
    "        print('Final epoch val loss = {:.3f}'.format(history.history['val_loss'][-1]))\n",
    "        print('Final epoch train acc = {:.3f}'.format(history.history['acc'][-1]))\n",
    "        print('Final epoch val acc = {:.3f}'.format(history.history['val_acc'][-1]))\n",
    "        print('Final epoch train mean_iou = {:.3f}'.format(history.history['mean_iou'][-1]))\n",
    "        print('Final epoch val mean_iou = {:.3f}'.format(history.history['val_mean_iou'][-1]))\n",
    "        \n",
    "        sub_dict = test_pred(test_gen, test_filenames)\n",
    "        \n",
    "        # save dictionary as csv file\n",
    "        sub = pd.DataFrame.from_dict(sub_dict,orient='index')\n",
    "        sub.index.names = ['patientId']\n",
    "        sub.columns = ['PredictionString']\n",
    "        sub.to_csv('submission' + str(n_fold) + '.csv')\n",
    "        \n",
    "else:\n",
    "    kf = KFold(n_splits=n_splits, random_state=SEED)\n",
    "    for n_fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "        train_gen = generator(folder, X[train_idx], pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=True, predict=False)\n",
    "        valid_gen = generator(folder, X[val_idx], pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=False, predict=False)\n",
    "        history = model.fit_generator(train_gen, validation_data=valid_gen, callbacks=[learning_rate], epochs=n_epochs, shuffle=True)\n",
    "        \n",
    "        valid_gen = generator(folder, X[val_idx], pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=False, predict=True)\n",
    "        oof_dict = test_pred(valid_gen, X[val_idx])\n",
    "        \n",
    "        # save dictionary as csv file\n",
    "        oof = pd.DataFrame.from_dict(oof_dict,orient='index')\n",
    "        oof.index.names = ['patientId']\n",
    "        oof.columns = ['PredictionString']\n",
    "        oof.to_csv('oof_preds' + str(n_fold) + '.csv')\n",
    "        \n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(131)\n",
    "        plt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "        plt.plot(history.epoch, history.history[\"val_loss\"], label=\"Valid loss\")\n",
    "        plt.legend()\n",
    "        plt.subplot(132)\n",
    "        plt.plot(history.epoch, history.history[\"acc\"], label=\"Train accuracy\")\n",
    "        plt.plot(history.epoch, history.history[\"val_acc\"], label=\"Valid accuracy\")\n",
    "        plt.legend()\n",
    "        plt.subplot(133)\n",
    "        plt.plot(history.epoch, history.history[\"mean_iou\"], label=\"Train iou\")\n",
    "        plt.plot(history.epoch, history.history[\"val_mean_iou\"], label=\"Valid iou\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print('Final epoch train loss = {:.3f}'.format(history.history['loss'][-1]))\n",
    "        print('Final epoch val loss = {:.3f}'.format(history.history['val_loss'][-1]))\n",
    "        print('Final epoch train acc = {:.3f}'.format(history.history['acc'][-1]))\n",
    "        print('Final epoch val acc = {:.3f}'.format(history.history['val_acc'][-1]))\n",
    "        print('Final epoch train mean_iou = {:.3f}'.format(history.history['mean_iou'][-1]))\n",
    "        print('Final epoch val mean_iou = {:.3f}'.format(history.history['val_mean_iou'][-1]))\n",
    "        \n",
    "        sub_dict = test_pred(test_gen, test_filenames)\n",
    "        \n",
    "        # save dictionary as csv file\n",
    "        sub = pd.DataFrame.from_dict(sub_dict,orient='index')\n",
    "        sub.index.names = ['patientId']\n",
    "        sub.columns = ['PredictionString']\n",
    "        sub.to_csv('submission' + str(n_fold) + '.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "1111 555 1111\n",
    "555 1111 555\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning rate: 0.00042\n",
    "beta (momentum): 0.94\n",
    "batch size: 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define iou or jaccard loss function\n",
    "def iou_loss(y_true, y_pred):\n",
    "    y_true = tf.reshape(y_true, [-1])\n",
    "    y_pred = tf.reshape(y_pred, [-1])\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    score = (intersection + 1.) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection + 1.)\n",
    "    return 1 - score\n",
    "\n",
    "# combine bce loss and iou loss\n",
    "def iou_bce_loss(y_true, y_pred):\n",
    "    return 0.5 * keras.losses.binary_crossentropy(y_true, y_pred) + 0.5 * iou_loss(y_true, y_pred)\n",
    "    \n",
    "# mean iou as a metric\n",
    "def mean_iou(y_true, y_pred):\n",
    "    y_pred = tf.round(y_pred)\n",
    "    intersect = tf.reduce_sum(y_true * y_pred, axis=[1, 2, 3])\n",
    "    union = tf.reduce_sum(y_true, axis=[1, 2, 3]) + tf.reduce_sum(y_pred, axis=[1, 2, 3])\n",
    "    smooth = tf.ones(tf.shape(intersect))\n",
    "    return tf.reduce_mean((intersect + smooth) / (union - intersect + smooth))\n",
    "\n",
    "# create network and compiler\n",
    "model = create_network(input_size=IMAGE_SIZE, channels=32, n_blocks=2, depth=4)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=iou_bce_loss,\n",
    "              metrics=['accuracy', mean_iou])\n",
    "\n",
    "\n",
    "# create network and compiler\n",
    "model = create_network(input_size=IMAGE_SIZE, channels=32, n_blocks=2, depth=nn_depth)\n",
    "model.compile(optimizer='adam',\n",
    "              loss=iou_bce_loss,\n",
    "              metrics=['accuracy', mean_iou])\n",
    "\n",
    "# cosine learning rate annealing\n",
    "def cosine_annealing(x):\n",
    "    epochs = 20\n",
    "    return lr*(np.cos(np.pi*x/epochs)+1.)/2\n",
    "learning_rate = tf.keras.callbacks.LearningRateScheduler(cosine_annealing)\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and shuffle filenames\n",
    "folder = 'rsna-pneumonia/stage_2_test_images'\n",
    "test_filenames = os.listdir(folder)\n",
    "#test_filenames = test_filenames[:1000]\n",
    "print('n test samples:', len(test_filenames))\n",
    "\n",
    "\n",
    "# create test generator with predict flag set to True\n",
    "test_gen = generator(folder, test_filenames, None, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=False, predict=True)\n",
    "\n",
    "def test_pred(test_gen, test_filenames):\n",
    "\n",
    "    # create submission dictionary\n",
    "    submission_dict = {}\n",
    "    # loop through testset\n",
    "    for imgs, filenames in test_gen:\n",
    "        # predict batch of images\n",
    "        preds = model.predict(imgs)\n",
    "\n",
    "        # loop through batch\n",
    "        for pred, filename in zip(preds, filenames):\n",
    "            \n",
    "            # resize predicted mask\n",
    "            pred = resize(pred, (1024, 1024), mode='reflect')\n",
    "            # threshold predicted mask\n",
    "            comp = pred[:, :, 0] > 0.5\n",
    "            # apply connected components\n",
    "            comp = measure.label(comp)\n",
    "            # apply bounding boxes\n",
    "            predictionString = ''\n",
    "            for region in measure.regionprops(comp):\n",
    "                # retrieve x, y, height and width\n",
    "                y, x, y2, x2 = region.bbox\n",
    "                height = y2 - y\n",
    "                width = x2 - x\n",
    "                # proxy for confidence score\n",
    "                conf = np.mean(pred[y:y+height, x:x+width])\n",
    "                # add to predictionString\n",
    "                predictionString += str(conf) + ' ' + str(x) + ' ' + str(y) + ' ' + str(width) + ' ' + str(height) + ' '\n",
    "            \n",
    "            # add filename and predictionString to dictionary\n",
    "            filename = filename.split('.')[0]\n",
    "            submission_dict[filename] = predictionString\n",
    "        # stop if we've got them all\n",
    "        if len(submission_dict) >= len(test_filenames):\n",
    "            break\n",
    "\n",
    "    print(\"Done predicting...\")\n",
    "    \n",
    "    return submission_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and validation generators\n",
    "folder = 'rsna-pneumonia/stage_2_train_images'\n",
    "\n",
    "if stratified == True:\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=SEED, shuffle=True)\n",
    "    for n_fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "        train_gen = generator(folder, X[train_idx], pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=True, predict=False)\n",
    "        valid_gen = generator(folder, X[val_idx], pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=False, predict=False)\n",
    "        print(train_gen)\n",
    "        print(valid_gen)\n",
    "        history = model.fit_generator(train_gen, validation_data=valid_gen, callbacks=[learning_rate], epochs=n_epochs, shuffle=True)\n",
    "        \n",
    "        valid_gen = generator(folder, X[val_idx], pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=False, predict=True)\n",
    "        oof_dict = test_pred(valid_gen, X[val_idx])\n",
    "        \n",
    "        # save dictionary as csv file\n",
    "        oof = pd.DataFrame.from_dict(oof_dict,orient='index')\n",
    "        oof.index.names = ['patientId']\n",
    "        oof.columns = ['PredictionString']\n",
    "        oof.to_csv('oof_preds' + str(n_fold) + '.csv')\n",
    "        \n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(131)\n",
    "        plt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "        plt.plot(history.epoch, history.history[\"val_loss\"], label=\"Valid loss\")\n",
    "        plt.legend()\n",
    "        plt.subplot(132)\n",
    "        plt.plot(history.epoch, history.history[\"acc\"], label=\"Train accuracy\")\n",
    "        plt.plot(history.epoch, history.history[\"val_acc\"], label=\"Valid accuracy\")\n",
    "        plt.legend()\n",
    "        plt.subplot(133)\n",
    "        plt.plot(history.epoch, history.history[\"mean_iou\"], label=\"Train iou\")\n",
    "        plt.plot(history.epoch, history.history[\"val_mean_iou\"], label=\"Valid iou\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print('Final epoch train loss = {:.3f}'.format(history.history['loss'][-1]))\n",
    "        print('Final epoch val loss = {:.3f}'.format(history.history['val_loss'][-1]))\n",
    "        print('Final epoch train acc = {:.3f}'.format(history.history['acc'][-1]))\n",
    "        print('Final epoch val acc = {:.3f}'.format(history.history['val_acc'][-1]))\n",
    "        print('Final epoch train mean_iou = {:.3f}'.format(history.history['mean_iou'][-1]))\n",
    "        print('Final epoch val mean_iou = {:.3f}'.format(history.history['val_mean_iou'][-1]))\n",
    "        \n",
    "        sub_dict = test_pred(test_gen, test_filenames)\n",
    "        \n",
    "        # save dictionary as csv file\n",
    "        sub = pd.DataFrame.from_dict(sub_dict,orient='index')\n",
    "        sub.index.names = ['patientId']\n",
    "        sub.columns = ['PredictionString']\n",
    "        sub.to_csv('submission' + str(n_fold) + '.csv')\n",
    "        \n",
    "else:\n",
    "    kf = KFold(n_splits=n_splits, random_state=SEED)\n",
    "    for n_fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):\n",
    "        train_gen = generator(folder, X[train_idx], pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=True, augment=True, predict=False)\n",
    "        valid_gen = generator(folder, X[val_idx], pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=False, predict=False)\n",
    "        history = model.fit_generator(train_gen, validation_data=valid_gen, callbacks=[learning_rate], epochs=n_epochs, shuffle=True)\n",
    "        \n",
    "        valid_gen = generator(folder, X[val_idx], pneumonia_locations, batch_size=BATCH_SIZE, image_size=IMAGE_SIZE, shuffle=False, predict=True)\n",
    "        oof_dict = test_pred(valid_gen, X[val_idx])\n",
    "        \n",
    "        # save dictionary as csv file\n",
    "        oof = pd.DataFrame.from_dict(oof_dict,orient='index')\n",
    "        oof.index.names = ['patientId']\n",
    "        oof.columns = ['PredictionString']\n",
    "        oof.to_csv('oof_preds' + str(n_fold) + '.csv')\n",
    "        \n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(131)\n",
    "        plt.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
    "        plt.plot(history.epoch, history.history[\"val_loss\"], label=\"Valid loss\")\n",
    "        plt.legend()\n",
    "        plt.subplot(132)\n",
    "        plt.plot(history.epoch, history.history[\"acc\"], label=\"Train accuracy\")\n",
    "        plt.plot(history.epoch, history.history[\"val_acc\"], label=\"Valid accuracy\")\n",
    "        plt.legend()\n",
    "        plt.subplot(133)\n",
    "        plt.plot(history.epoch, history.history[\"mean_iou\"], label=\"Train iou\")\n",
    "        plt.plot(history.epoch, history.history[\"val_mean_iou\"], label=\"Valid iou\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        print('Final epoch train loss = {:.3f}'.format(history.history['loss'][-1]))\n",
    "        print('Final epoch val loss = {:.3f}'.format(history.history['val_loss'][-1]))\n",
    "        print('Final epoch train acc = {:.3f}'.format(history.history['acc'][-1]))\n",
    "        print('Final epoch val acc = {:.3f}'.format(history.history['val_acc'][-1]))\n",
    "        print('Final epoch train mean_iou = {:.3f}'.format(history.history['mean_iou'][-1]))\n",
    "        print('Final epoch val mean_iou = {:.3f}'.format(history.history['val_mean_iou'][-1]))\n",
    "        \n",
    "        sub_dict = test_pred(test_gen, test_filenames)\n",
    "        \n",
    "        # save dictionary as csv file\n",
    "        sub = pd.DataFrame.from_dict(sub_dict,orient='index')\n",
    "        sub.index.names = ['patientId']\n",
    "        sub.columns = ['PredictionString']\n",
    "        sub.to_csv('submission' + str(n_fold) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cf8889d2362d979c1ca60a3272c8483814f41f7f5def47ce260ee0771921932"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
